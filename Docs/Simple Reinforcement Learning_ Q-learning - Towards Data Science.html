<!DOCTYPE html>
<!-- saved from url=(0084)https://towardsdatascience.com/simple-reinforcement-learning-q-learning-fcddc4b6fe56 -->
<html lang="en" data-rh="lang"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"><script async="" src="./Simple Reinforcement Learning_ Q-learning - Towards Data Science_files/branch-latest.min.js.download"></script><script async="" src="./Simple Reinforcement Learning_ Q-learning - Towards Data Science_files/analytics.js.download"></script><script>!function(c,f){var t,o,i,e=[],r={passive:!0,capture:!0},n=new Date,a="pointerup",u="pointercancel";function p(n,e){t||(t=e,o=n,i=new Date,w(f),s())}function s(){0<=o&&o<i-n&&(e.forEach(function(n){n(o,t)}),e=[])}function l(n){if(n.cancelable){var e=(1e12<n.timeStamp?new Date:performance.now())-n.timeStamp;"pointerdown"==n.type?function(n,e){function t(){p(n,e),i()}function o(){i()}function i(){f(a,t,r),f(u,o,r)}c(a,t,r),c(u,o,r)}(e,n):p(e,n)}}function w(e){["click","mousedown","keydown","touchstart","pointerdown"].forEach(function(n){e(n,l,r)})}w(c),self.perfMetrics=self.perfMetrics||{},self.perfMetrics.onFirstInputDelay=function(n){e.push(n),s()}}(addEventListener,removeEventListener)</script><title>Simple Reinforcement Learning: Q-learning - Towards Data Science</title><meta data-rh="true" name="viewport" content="width=device-width,minimum-scale=1,initial-scale=1"><meta data-rh="true" name="theme-color" content="#000000"><meta data-rh="true" name="twitter:app:name:iphone" content="Medium"><meta data-rh="true" name="twitter:app:id:iphone" content="828256236"><meta data-rh="true" property="al:ios:app_name" content="Medium"><meta data-rh="true" property="al:ios:app_store_id" content="828256236"><meta data-rh="true" property="al:android:package" content="com.medium.reader"><meta data-rh="true" property="fb:app_id" content="542599432471018"><meta data-rh="true" property="og:site_name" content="Medium"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2019-07-01T18:25:40.339Z"><meta data-rh="true" name="title" content="Simple Reinforcement Learning: Q-learning - Towards Data Science"><meta data-rh="true" property="og:title" content="Simple Reinforcement Learning: Q-learning"><meta data-rh="true" property="twitter:title" content="Simple Reinforcement Learning: Q-learning"><meta data-rh="true" name="twitter:site" content="@TDataScience"><meta data-rh="true" name="twitter:app:url:iphone" content="medium://p/fcddc4b6fe56"><meta data-rh="true" property="al:android:url" content="medium://p/fcddc4b6fe56"><meta data-rh="true" property="al:ios:url" content="medium://p/fcddc4b6fe56"><meta data-rh="true" property="al:android:app_name" content="Medium"><meta data-rh="true" name="description" content="One of my favorite algorithms that I learned while taking a reinforcement learning course was q-learning. Probably because it was the easiest for me to understand and code, but also because it…"><meta data-rh="true" property="og:description" content="Introduction"><meta data-rh="true" property="twitter:description" content="Introduction"><meta data-rh="true" property="og:url" content="https://towardsdatascience.com/simple-reinforcement-learning-q-learning-fcddc4b6fe56"><meta data-rh="true" property="al:web:url" content="https://towardsdatascience.com/simple-reinforcement-learning-q-learning-fcddc4b6fe56"><meta data-rh="true" property="og:image" content="https://miro.medium.com/max/1200/1*OjizsKNU6_LyM3QW8is0Sg.jpeg"><meta data-rh="true" name="twitter:image:src" content="https://miro.medium.com/max/1200/1*OjizsKNU6_LyM3QW8is0Sg.jpeg"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="article:author" content="https://towardsdatascience.com/@violante.andre"><meta data-rh="true" name="author" content="Andre Violante"><meta data-rh="true" name="robots" content="index,follow"><meta data-rh="true" name="referrer" content="unsafe-url"><meta data-rh="true" name="twitter:label1" value="Reading time"><meta data-rh="true" name="twitter:data1" value="5 min read"><meta data-rh="true" name="parsely-post-id" content="fcddc4b6fe56"><link data-rh="true" rel="search" type="application/opensearchdescription+xml" title="Medium" href="https://towardsdatascience.com/osd.xml"><link data-rh="true" rel="apple-touch-icon" sizes="152x152" href="https://cdn-images-1.medium.com/fit/c/152/152/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="apple-touch-icon" sizes="120x120" href="https://cdn-images-1.medium.com/fit/c/120/120/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="apple-touch-icon" sizes="76x76" href="https://cdn-images-1.medium.com/fit/c/76/76/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="apple-touch-icon" sizes="60x60" href="https://cdn-images-1.medium.com/fit/c/60/60/1*8I-HPL0bfoIzGied-dzOvA.png"><link data-rh="true" rel="mask-icon" href="https://cdn-static-1.medium.com/_/fp/icons/monogram-mask.KPLCSFEZviQN0jQ7veN2RQ.svg" color="#171717"><link data-rh="true" id="glyph_link" rel="stylesheet" type="text/css" href="./Simple Reinforcement Learning_ Q-learning - Towards Data Science_files/m2.css"><link data-rh="true" rel="author" href="https://towardsdatascience.com/@violante.andre"><link data-rh="true" rel="canonical" href="https://towardsdatascience.com/simple-reinforcement-learning-q-learning-fcddc4b6fe56"><link data-rh="true" rel="alternate" href="android-app://com.medium.reader/https/medium.com/p/fcddc4b6fe56"><script data-rh="true">(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
ga('create', 'UA-24232453-2', 'auto');
ga('send', 'pageview');</script><link rel="preload" href="./Simple Reinforcement Learning_ Q-learning - Towards Data Science_files/16180790160.js.download" as="script"><style type="text/css" data-fela-rehydration="431" data-fela-type="STATIC">html{box-sizing:border-box}*, *:before, *:after{box-sizing:inherit}body{margin:0;padding:0;text-rendering:optimizeLegibility;-webkit-font-smoothing:antialiased;color:rgba(0,0,0,0.8);position:relative;min-height:100vh}h1, h2, h3, h4, h5, h6, dl, dd, ol, ul, menu, figure, blockquote, p, pre, form{margin:0}menu, ol, ul{padding:0;list-style:none;list-style-image:none}main{display:block}a{color:inherit;text-decoration:none}a, button, input{-webkit-tap-highlight-color:transparent}img, svg{vertical-align:middle}button{background:transparent;overflow:visible}button, input, optgroup, select, textarea{margin:0}</style><style type="text/css" data-fela-rehydration="431" data-fela-type="KEYFRAME">@-webkit-keyframes k1{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@-moz-keyframes k1{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@keyframes k1{0%{transform:scale(1)}50%{transform:scale(1.1)}100%{transform:scale(1)}}@-webkit-keyframes k2{0%{transform:scale(1);opacity:1}70%{transform:scale(1.4);opacity:0}100%{opacity:0}}@-moz-keyframes k2{0%{transform:scale(1);opacity:1}70%{transform:scale(1.4);opacity:0}100%{opacity:0}}@keyframes k2{0%{transform:scale(1);opacity:1}70%{transform:scale(1.4);opacity:0}100%{opacity:0}}</style><style type="text/css" data-fela-rehydration="431" data-fela-type="RULE">.a{font-family:medium-content-sans-serif-font, -apple-system, BlinkMacSystemFont, "Segoe UI", Roboto, Oxygen, Ubuntu, Cantarell, "Open Sans", "Helvetica Neue", sans-serif}.b{font-weight:400}.c{background-color:rgba(255, 255, 255, 1)}.l{height:100vh}.m{width:100vw}.n{display:flex}.o{align-items:center}.p{justify-content:center}.q{fill:rgba(0, 0, 0, 0.84)}.r{display:block}.s{position:fixed}.t{top:0}.u{left:0}.v{right:0}.w{z-index:500}.x{box-shadow:0 4px 12px 0 rgba(0, 0, 0, 0.05)}.ai{max-width:1192px}.aj{min-width:0}.ak{width:100%}.al{height:65px}.ao{flex:1 0 auto}.ap{flex:0 0 auto}.aq{font-family:medium-content-sans-serif-font, "Lucida Grande", "Lucida Sans Unicode", "Lucida Sans", Geneva, Arial, sans-serif}.ar{font-style:normal}.as{line-height:20px}.at{font-size:15.8px}.au{letter-spacing:0px}.av{color:rgba(0, 0, 0, 0.54)}.aw{fill:rgba(0, 0, 0, 0.54)}.ax{justify-content:flex-end}.ay{margin-top:16px}.az{margin-bottom:16px}.ba{display:inherit}.bb{max-width:210px}.bc{text-overflow:ellipsis}.bd{overflow:hidden}.be{white-space:nowrap}.bf{display:inline-block}.bg{border:none}.bh{outline:none}.bi{font:inherit}.bj{font-size:16px}.bk{opacity:0}.bl{position:relative}.bm{width:0px}.bn{transition:width 140ms ease-in}.bo{color:inherit}.bp{fill:inherit}.bq{font-size:inherit}.br{border:inherit}.bs{font-family:inherit}.bt{letter-spacing:inherit}.bu{font-weight:inherit}.bv{padding:0}.bw{margin:0}.bx:hover{cursor:pointer}.by:hover{color:rgba(0, 0, 0, 0.9)}.bz:hover{fill:rgba(0, 0, 0, 0.9)}.ca:focus{outline:none}.cb:disabled{cursor:default}.cc:disabled{color:rgba(0, 0, 0, 0.54)}.cd:disabled{fill:rgba(0, 0, 0, 0.54)}.ce{margin-left:16px}.cf{margin-right:10px}.ci{display:none}.ck{margin-right:16px}.cl{margin:15px 0}.cm{visibility:hidden}.cn{padding:4px 12px}.co{color:rgba(0, 0, 0, 0.84)}.cp{background:0}.cq{border-color:rgba(0, 0, 0, 0.54)}.cr:hover{color:rgba(0, 0, 0, 0.97)}.cs:hover{fill:rgba(0, 0, 0, 0.97)}.ct:hover{border-color:rgba(0, 0, 0, 0.84)}.cu:disabled{fill:rgba(0, 0, 0, 0.76)}.cv:disabled{border-color:rgba(0, 0, 0, 0.2)}.cw:disabled{cursor:inherit}.cx:disabled:hover{color:rgba(0, 0, 0, 0.54)}.cy:disabled:hover{fill:rgba(0, 0, 0, 0.76)}.cz:disabled:hover{border-color:rgba(0, 0, 0, 0.2)}.da{border-radius:4px}.db{border-width:1px}.dc{border-style:solid}.dd{box-sizing:border-box}.de{text-decoration:none}.df{padding-bottom:10px}.dg{padding-top:10px}.dh{border-radius:50%}.di{height:32px}.dj{width:32px}.dk{border-top:none}.dl{background-color:rgba(53, 88, 118, 1)}.dn{height:54px}.do{margin-right:40px}.dp{height:36px}.dq{width:100px}.dr{overflow:auto}.ds{flex:0 1 auto}.dt{list-style-type:none}.du{line-height:40px}.dv{overflow-x:auto}.dw{align-items:flex-start}.dx{margin-top:20px}.dy{padding-top:20px}.dz{height:80px}.ea{height:20px}.eb{margin-right:15px}.ec{margin-left:15px}.ed:first-child{margin-left:0}.ee{min-width:1px}.ef{background-color:rgba(197, 210, 225, 1)}.eg{font-weight:300}.eh{font-size:15px}.ei{color:rgba(197, 210, 225, 1)}.ej{text-transform:uppercase}.ek{letter-spacing:1px}.el:hover{color:rgba(251, 255, 255, 1)}.em:hover{fill:rgba(233, 241, 250, 1)}.en:disabled{color:rgba(150, 171, 191, 1)}.eo:disabled{fill:rgba(150, 171, 191, 1)}.ep{margin-bottom:0px}.eq{height:119px}.et{padding-left:24px}.eu{padding-right:24px}.ev{margin-left:auto}.ew{margin-right:auto}.ex{max-width:728px}.ey{flex-direction:column}.ez{position:absolute}.fa{top:calc(100vh + 100px)}.fb{bottom:calc(100vh + 100px)}.fc{width:10px}.fd{pointer-events:none}.fe{word-break:break-word}.ff{word-wrap:break-word}.fg:after{display:block}.fh:after{content:""}.fi:after{clear:both}.fj{max-width:680px}.fk{line-height:1.23}.fl{letter-spacing:0}.fm{font-family:medium-content-title-font, Georgia, Cambria, "Times New Roman", Times, serif}.fx{margin-bottom:-0.27em}.gd{margin-top:32px}.ge{justify-content:space-between}.gi{height:48px}.gj{width:48px}.gk{margin-left:12px}.gl{margin-bottom:2px}.gn{max-height:20px}.go{display:-webkit-box}.gp{-webkit-line-clamp:1}.gq{-webkit-box-orient:vertical}.gr:hover{text-decoration:underline}.gs{margin-left:8px}.gt{padding:0px 8px}.gu{color:rgba(90, 118, 144, 1)}.gv{fill:rgba(102, 138, 170, 1)}.gw{border-color:rgba(102, 138, 170, 1)}.gx:hover{color:rgba(84, 108, 131, 1)}.gy:hover{fill:rgba(90, 118, 144, 1)}.gz:hover{border-color:rgba(90, 118, 144, 1)}.ha{line-height:18px}.hb{align-items:flex-end}.hj{padding-right:8px}.hk{margin-right:-6px}.hl{fill:rgba(0, 0, 0, 0.76)}.hm{max-width:4592px}.hs{clear:both}.ht{transition:transform 300ms cubic-bezier(0.2, 0, 0.2, 1)}.hu{cursor:zoom-in}.hv{z-index:auto}.hw{transition:opacity 100ms 400ms}.hx{height:100%}.hy{will-change:transform}.hz{transform:translateZ(0)}.ia{margin:auto}.ib{background-color:rgba(0, 0, 0, 0.05)}.ic{padding-bottom:75.08710801393728%}.id{filter:blur(20px)}.ie{transform:scale(1.1)}.if{visibility:visible}.ig{background:rgba(255, 255, 255, 1)}.ih{line-height:1.4}.ii{margin-top:10px}.ij{text-align:center}.im{background-repeat:repeat-x}.in{background-image:linear-gradient(to right,rgba(0, 0, 0, 0.84) 100%,rgba(0, 0, 0, 0.84) 0);background-image:url('data:image/svg+xml;utf8,<svg preserveAspectRatio="none" viewBox="0 0 1 1" xmlns="http://www.w3.org/2000/svg"><line x1="0" y1="0" x2="1" y2="1" stroke="rgba(0, 0, 0, 0.84)" /></svg>')}.io{background-size:1px 1px}.ip{background-position:0 1.05em;background-position:0 calc(1em + 1px)}.iq{line-height:1.12}.ir{letter-spacing:-0.022em}.is{font-weight:600}.jb{margin-bottom:-0.28em}.jc{line-height:1.58}.jd{letter-spacing:-0.004em}.je{font-family:medium-content-serif-font, Georgia, Cambria, "Times New Roman", Times, serif}.jp{margin-bottom:-0.46em}.jq{font-style:italic}.jr{padding:2px 4px}.js{font-size:75%}.jt> strong{font-family:inherit}.ju{font-family:Menlo, Monaco, "Courier New", Courier, monospace}.jv{padding:20px}.jw{background:rgba(0, 0, 0, 0.05)}.jx{line-height:1.18}.jy{margin-top:-0.09em}.jz{margin-bottom:-0.09em}.ka{white-space:pre-wrap}.kl{font-weight:700}.km{list-style-type:decimal}.kn{margin-left:30px}.ko{padding-left:0px}.ku{will-change:opacity}.kv{width:188px}.kw{left:50%}.kx{transform:translateX(406px)}.ky{top:calc(65px + 54px + 14px)}.lb{top:calc(65px + 54px + 40px)}.ld{width:131px}.le{padding-bottom:28px}.lf{border-bottom:1px solid rgba(0, 0, 0, 0.1)}.lg{font-size:18px}.lh{padding-bottom:20px}.li{padding-top:2px}.lj{max-height:120px}.lk{-webkit-line-clamp:6}.ll{padding-top:28px}.lm{margin-bottom:19px}.ln{margin-left:-5px}.lo{margin-right:5px}.lp{outline:0}.lq{border:0}.lr{user-select:none}.ls{cursor:pointer}.lt> svg{pointer-events:none}.lu:active{border-style:none}.lv{-webkit-user-select:none}.lw:focus{fill:rgba(90, 118, 144, 1)}.lx{margin-top:5px}.ly button{text-align:left}.lz{margin-left:-3px}.ma{margin-top:40px}.mb{flex-wrap:wrap}.mc{margin-top:25px}.md{margin-right:8px}.me{margin-bottom:8px}.mf{border-radius:3px}.mg{padding:5px 10px}.mh{line-height:22px}.mi{margin-top:15px}.mj{border:1px solid rgba(0, 0, 0, 0.1)}.mk{height:60px}.ml{width:60px}.my:active{border-style:solid}.mz{z-index:2}.nb{padding-top:32px}.nc{border-top:1px solid rgba(0, 0, 0, 0.1)}.nd{margin-bottom:25px}.ne{margin-bottom:32px}.nf{min-height:80px}.nk{width:80px}.nl{padding-left:102px}.nn{letter-spacing:0.05em}.no{margin-bottom:6px}.np{font-size:28px}.nq{line-height:36px}.nr{max-width:555px}.ns{max-width:450px}.nt{line-height:24px}.nv{max-width:550px}.nw{padding-top:25px}.nx{color:rgba(0, 0, 0, 0.76)}.ny{opacity:1}.nz{border:1px solid rgba(102, 138, 170, 1)}.oa{margin-top:64px}.ob{background-color:rgba(0, 0, 0, 0.02)}.oc{padding:60px 0}.od{background-color:rgba(0, 0, 0, 0.9)}.ou{padding-bottom:48px}.ov{border-bottom:1px solid rgba(255, 255, 255, 0.54)}.ow{margin:0 -12px}.ox{margin:0 12px}.oy{flex:1 1 0}.oz{padding-bottom:12px}.pa:hover{color:rgba(255, 255, 255, 0.99)}.pb:hover{fill:rgba(255, 255, 255, 0.99)}.pc:disabled{color:rgba(255, 255, 255, 0.7)}.pd:disabled{fill:rgba(255, 255, 255, 0.7)}.pe{color:rgba(255, 255, 255, 0.98)}.pf{fill:rgba(255, 255, 255, 0.98)}.pg{text-align:inherit}.ph{font-size:21.6px}.pi{letter-spacing:-0.32px}.pj{color:rgba(255, 255, 255, 0.7)}.pk{fill:rgba(255, 255, 255, 0.7)}.pl{text-decoration:underline}.pm{padding-bottom:8px}.pn{padding-top:8px}.po{width:200px}.pq{-webkit-user-select:none}</style><style type="text/css" data-fela-rehydration="431" data-fela-type="RULE" media="all and (min-width: 1080px)">.d{display:none}.ah{margin:0 64px}.fv{font-size:40px}.fw{margin-top:0.78em}.gc{line-height:48px}.hi{margin-left:30px}.hr{margin-top:56px}.iz{font-size:34px}.ja{margin-top:1.95em}.jn{font-size:21px}.jo{margin-top:0.86em}.kf{margin-top:1.91em}.kk{margin-top:2em}.kt{margin-top:1.05em}.or{padding-left:64px}.os{padding-right:64px}.ot{max-width:1320px}</style><style type="text/css" data-fela-rehydration="431" data-fela-type="RULE" media="all and (max-width: 1079.98px)">.e{display:none}.hh{margin-left:30px}.ik{margin-left:auto}.il{text-align:center}.oo{padding-left:64px}.op{padding-right:64px}.oq{max-width:1080px}</style><style type="text/css" data-fela-rehydration="431" data-fela-type="RULE" media="all and (max-width: 903.98px)">.f{display:none}.cj{display:flex}.hg{margin-left:30px}.ol{padding-left:48px}.om{padding-right:48px}.on{max-width:904px}</style><style type="text/css" data-fela-rehydration="431" data-fela-type="RULE" media="all and (max-width: 727.98px)">.g{display:none}.am{height:56px}.an{display:flex}.cg{margin-left:10px}.ch{margin-right:10px}.dm{display:block}.er{margin-bottom:0px}.es{height:110px}.gg{margin-top:32px}.gh{flex-direction:column-reverse}.he{margin-bottom:30px}.hf{margin-left:0px}.ng{margin-bottom:24px}.nh{align-items:center}.ni{width:102px}.nj{position:relative}.nm{padding-left:0}.nu{margin-top:24px}.oe{padding:32px 0}.oi{padding-left:24px}.oj{padding-right:24px}.ok{max-width:728px}.pp{width:140px}</style><style type="text/css" data-fela-rehydration="431" data-fela-type="RULE" media="all and (max-width: 551.98px)">.h{display:none}.ac{margin:0 24px}.fn{font-size:30px}.fo{margin-top:0.72em}.fy{line-height:40px}.gf{margin-top:32px}.gm{margin-bottom:0px}.hc{margin-bottom:30px}.hd{margin-left:0px}.hn{margin-top:40px}.it{margin-top:1.2em}.jf{font-size:18px}.jg{margin-top:0.67em}.kb{margin-top:1.41em}.kg{margin-top:1.56em}.kp{margin-top:1.34em}.of{padding-left:24px}.og{padding-right:24px}.oh{max-width:552px}</style><style type="text/css" data-fela-rehydration="431" data-fela-type="RULE" media="all and (min-width: 904px) and (max-width: 1079.98px)">.i{display:none}.ag{margin:0 64px}.ft{font-size:40px}.fu{margin-top:0.78em}.gb{line-height:48px}.hq{margin-top:56px}.ix{font-size:34px}.iy{margin-top:1.95em}.jl{font-size:21px}.jm{margin-top:0.86em}.ke{margin-top:1.91em}.kj{margin-top:2em}.ks{margin-top:1.05em}</style><style type="text/css" data-fela-rehydration="431" data-fela-type="RULE" media="all and (min-width: 728px) and (max-width: 903.98px)">.j{display:none}.af{margin:0 48px}.fr{font-size:40px}.fs{margin-top:0.78em}.ga{line-height:48px}.hp{margin-top:56px}.iv{font-size:34px}.iw{margin-top:1.95em}.jj{font-size:21px}.jk{margin-top:0.86em}.kd{margin-top:1.91em}.ki{margin-top:2em}.kr{margin-top:1.05em}</style><style type="text/css" data-fela-rehydration="431" data-fela-type="RULE" media="all and (min-width: 552px) and (max-width: 727.98px)">.k{display:none}.ae{margin:0 24px}.fp{font-size:30px}.fq{margin-top:0.72em}.fz{line-height:40px}.ho{margin-top:40px}.iu{margin-top:1.2em}.jh{font-size:18px}.ji{margin-top:0.67em}.kc{margin-top:1.41em}.kh{margin-top:1.56em}.kq{margin-top:1.34em}</style><style type="text/css" data-fela-rehydration="431" data-fela-type="RULE" media="print">.ab{display:none}</style><style type="text/css" data-fela-rehydration="431" data-fela-type="RULE" media="(prefers-reduced-motion: no-preference)">.y{transition:transform 300ms ease}.z{will-change:transform}.kz{transition:opacity 200ms}.mm{transition:border-color 150ms ease}.mn::before{background:
      radial-gradient(circle, rgba(90, 118, 144, 1) 60%, transparent 70%)
    }.mo::before{border-radius:50%}.mp::before{content:""}.mq::before{display:block}.mr::before{z-index:0}.ms::before{left:0}.mt::before{height:100%}.mu::before{position:absolute}.mv::before{top:0}.mw::before{width:100%}.mx:hover::before{animation:k2 2000ms infinite cubic-bezier(.1,.12,.25,1)}.na{transition:fill 200ms ease}</style><style type="text/css" data-fela-rehydration="431" data-fela-type="RULE" media="all and (max-width: 1230px)">.la{display:none}</style><style type="text/css" data-fela-rehydration="431" data-fela-type="RULE" media="all and (max-width: 1198px)">.lc{display:none}</style><link rel="icon" href="https://miro.medium.com/fit/c/160/160/1*ChFMdf--f5jbm-AYv6VdYA@2x.png" data-rh="true"><script type="application/ld+json" data-rh="true">{"@context":"http:\u002F\u002Fschema.org","@type":"NewsArticle","image":["https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F1200\u002F1*OjizsKNU6_LyM3QW8is0Sg.jpeg"],"url":"https:\u002F\u002Ftowardsdatascience.com\u002Fsimple-reinforcement-learning-q-learning-fcddc4b6fe56","dateCreated":"2019-03-18T20:41:04.323Z","datePublished":"2019-03-18T20:41:04.323Z","dateModified":"2019-07-01T18:25:40.652Z","headline":"Simple Reinforcement Learning: Q-learning","name":"Simple Reinforcement Learning: Q-learning","description":"One of my favorite algorithms that I learned while taking a reinforcement learning course was q-learning. Probably because it was the easiest for me to understand and code, but also because it…","identifier":"fcddc4b6fe56","keywords":["Lite:true","Tag:Machine Learning","Tag:Reinforcement Learning","Tag:Q Learning","Tag:Data Science","Publication:towards-data-science","Elevated:false","LockedPostSource:LOCKED_POST_SOURCE_NONE","LayerCake:0"],"author":{"@type":"Person","name":"Andre Violante","url":"https:\u002F\u002Ftowardsdatascience.com\u002F@violante.andre"},"creator":["Andre Violante"],"publisher":{"@type":"Organization","name":"Towards Data Science","url":"towardsdatascience.com","logo":{"@type":"ImageObject","width":165,"height":60,"url":"https:\u002F\u002Fmiro.medium.com\u002Fmax\u002F206\u002F1*mG6i4Bh_LgixUYXJgQpYsg@2x.png"}},"mainEntityOfPage":"https:\u002F\u002Ftowardsdatascience.com\u002Fsimple-reinforcement-learning-q-learning-fcddc4b6fe56"}</script><script type="text/javascript" data-rh="true">(function(b,r,a,n,c,h,_,s,d,k){if(!b[n]||!b[n]._q){for(;s<_.length;)c(h,_[s++]);d=r.createElement(a);d.async=1;d.src="https://cdn.branch.io/branch-latest.min.js";k=r.getElementsByTagName(a)[0];k.parentNode.insertBefore(d,k);b[n]=h}})(window,document,"script","branch",function(b,r){b[r]=function(){b._q.push([r,arguments])}},{_q:[],_v:1},"addListener applyCode autoAppIndex banner closeBanner closeJourney creditHistory credits data deepview deepviewCta first getCode init link logout redeem referrals removeListener sendSMS setBranchViewData setIdentity track validateCode trackCommerceEvent logEvent".split(" "), 0);
branch.init('key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm', {metadata: {}, 'no_journeys': true, 'disable_exit_animation': true, 'disable_entry_animation': true, 'tracking_disabled': null}, function(err, data) {});</script><script charset="utf-8" src="./Simple Reinforcement Learning_ Q-learning - Towards Data Science_files/vendors_tracing.ce8c97b6.chunk.js.download"></script><script charset="utf-8" src="./Simple Reinforcement Learning_ Q-learning - Towards Data Science_files/tracing.92a145d0.chunk.js.download"></script><script type="text/javascript" async="" src="./Simple Reinforcement Learning_ Q-learning - Towards Data Science_files/_r"></script></head><body data-gr-c-s-loaded="true"><div id="root"><div class="a b c"><div class="d e f g h i j k"></div><script>document.domain = document.domain;</script><script>window.PARSELY = window.PARSELY || {autotrack: false}</script><nav class="r s t u v c w x y z ab" style=""><div class="branch-journeys-top"><div class="r c"><div class="n p"><div class="ac ae af ag ah ai aj ak"><div class="al n o am an"><div class="n o ao w"><a href="https://medium.com/?source=post_page-----fcddc4b6fe56----------------------" aria-label="Homepage" rel="noopener"><svg width="35" height="35" viewBox="5 5 35 35" class="q"><path d="M5 40V5h35v35H5zm8.56-12.63c0 .56-.03.69-.32 1.03L10.8 31.4v.4h6.97v-.4L15.3 28.4c-.29-.34-.34-.5-.34-1.03v-8.95l6.13 13.36h.71l5.26-13.36v10.64c0 .3 0 .35-.19.53l-1.85 1.8v.4h9.2v-.4l-1.83-1.8c-.18-.18-.2-.24-.2-.53V15.94c0-.3.02-.35.2-.53l1.82-1.8v-.4h-6.47l-4.62 11.55-5.2-11.54h-6.8v.4l2.15 2.63c.24.3.29.37.29.77v10.35z"></path></svg></a></div><div class="r ap w"><span class="aq b ar as at au r av aw"><div class="n o ax"><div class="n f"><div class="bf" aria-hidden="true"><div class="n"><button class="bo bp bq br bs bt bu bv bw bx by bz ca cb cc cd"><svg width="25" height="25" viewBox="0 0 25 25" class="ce cf r cg ch"><path d="M20.07 18.93l-4.16-4.15a6 6 0 1 0-.88.88l4.15 4.16a.62.62 0 1 0 .89-.89zM6.5 11a4.75 4.75 0 1 1 9.5 0 4.75 4.75 0 0 1-9.5 0z"></path></svg></button><input class="bg bh bi bj as bk bl bm bn" placeholder="Search Towards Data Science" value=""></div></div></div><div class="ci cj"><a href="https://towardsdatascience.com/search?source=post_page-----fcddc4b6fe56----------------------" class="bo bp bq br bs bt bu bv bw bx by bz ca cb cc cd" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25" class="ce ck r cg ch"><path d="M20.07 18.93l-4.16-4.15a6 6 0 1 0-.88.88l4.15 4.16a.62.62 0 1 0 .89-.89zM6.5 11a4.75 4.75 0 1 1 9.5 0 4.75 4.75 0 0 1-9.5 0z"></path></svg></a></div><a href="https://medium.com/me/list/queue?source=post_page-----fcddc4b6fe56----------------------" class="bo bp bq br bs bt bu bv bw bx by bz ca cb cc cd" rel="noopener"><svg width="25" height="25" viewBox="0 0 25 25" class="ck r g"><path d="M16 6a2 2 0 0 1 2 2v13.66h-.01a.5.5 0 0 1-.12.29.5.5 0 0 1-.7.03l-5.67-4.13-5.66 4.13a.5.5 0 0 1-.7-.03.48.48 0 0 1-.13-.29H5V8c0-1.1.9-2 2-2h9zM6 8v12.64l5.16-3.67a.49.49 0 0 1 .68 0L17 20.64V8a1 1 0 0 0-1-1H7a1 1 0 0 0-1 1z"></path><path d="M21 5v13.66h-.01a.5.5 0 0 1-.12.29.5.5 0 0 1-.7.03l-.17-.12V5a1 1 0 0 0-1-1h-9a1 1 0 0 0-1 1H8c0-1.1.9-2 2-2h9a2 2 0 0 1 2 2z"></path></svg></a><div class="ck n ch"><div class="bf" aria-hidden="true"><button class="bo bp bq br bs bt bu bv bw bx by bz ca cb cc cd r"><svg width="25" height="25" viewBox="-293 409 25 25" class="cl r"><path d="M-273.33 423.67l-1.67-1.52v-3.65a5.5 5.5 0 0 0-6.04-5.47 5.66 5.66 0 0 0-4.96 5.71v3.41l-1.68 1.55a1 1 0 0 0-.32.74V427a1 1 0 0 0 1 1h3.49a3.08 3.08 0 0 0 3.01 2.45 3.08 3.08 0 0 0 3.01-2.45h3.49a1 1 0 0 0 1-1v-2.59a1 1 0 0 0-.33-.74zm-7.17 5.63c-.84 0-1.55-.55-1.81-1.3h3.62a1.92 1.92 0 0 1-1.81 1.3zm6.35-2.45h-12.7v-2.35l1.63-1.5c.24-.22.37-.53.37-.85v-3.41a4.51 4.51 0 0 1 3.92-4.57 4.35 4.35 0 0 1 4.78 4.33v3.65c0 .32.14.63.38.85l1.62 1.48v2.37z"></path></svg></button></div></div><div class="if" id="li-post-page-navbar-upsell-button"><div class="ck r g"><div><a href="https://medium.com/membership?source=upgrade_membership---nav_full------------------------" class="cn co q cp cq cr cs ct bx cc cu cv cw cx cy cz da aq b ar as at au db dc dd bf de ca" rel="noopener">Upgrade</a></div></div></div><div class="n" aria-hidden="true"><div class="df dg n o"><button class="bo bp bq br bs bt bu bv bw bx by bz ca cb cc cd"><img alt="Hayder Endo Pérez" class="r dh di dj" src="./Simple Reinforcement Learning_ Q-learning - Towards Data Science_files/0_Q-PdbCU7WM5apRrk_" width="32" height="32"></button></div></div></div></span></div></div></div></div></div><div class="dk r dl dm"><div class="n p"><div class="ac ae af ag ah ai aj ak"><div class="dn bd n o"><div class="do r ap"><a href="https://towardsdatascience.com/?source=post_page-----fcddc4b6fe56----------------------" rel="noopener"><div class="dp dq r"><img alt="Towards Data Science" class="" src="./Simple Reinforcement Learning_ Q-learning - Towards Data Science_files/1_mG6i4Bh_LgixUYXJgQpYsg@2x.png" width="100" height="36"></div></a></div><div class="dr r ds"><ul class="dt bw du be dv n dw g dx dy dz"><li class="n o ea eb ec ed"><span class="aq eg eh as ei ej ek"><a href="https://towardsdatascience.com/data-science/home?source=post_page-----fcddc4b6fe56----------------------" class="bo bp bq br bs bt bu bv bw bx el em ca cb en eo" rel="noopener">Data Science</a></span></li><li class="n o ea eb ec ed"><span class="aq eg eh as ei ej ek"><a href="https://towardsdatascience.com/machine-learning/home?source=post_page-----fcddc4b6fe56----------------------" class="bo bp bq br bs bt bu bv bw bx el em ca cb en eo" rel="noopener">Machine Learning</a></span></li><li class="n o ea eb ec ed"><span class="aq eg eh as ei ej ek"><a href="https://towardsdatascience.com/programming/home?source=post_page-----fcddc4b6fe56----------------------" class="bo bp bq br bs bt bu bv bw bx el em ca cb en eo" rel="noopener">Programming</a></span></li><li class="n o ea eb ec ed"><span class="aq eg eh as ei ej ek"><a href="https://towardsdatascience.com/data-visualization/home?source=post_page-----fcddc4b6fe56----------------------" class="bo bp bq br bs bt bu bv bw bx el em ca cb en eo" rel="noopener">Visualization</a></span></li><li class="n o ea eb ec ed"><span class="aq eg eh as ei ej ek"><a href="https://towardsdatascience.com/artificial-intelligence/home?source=post_page-----fcddc4b6fe56----------------------" class="bo bp bq br bs bt bu bv bw bx el em ca cb en eo" rel="noopener">AI</a></span></li><li class="n o ea eb ec ed"><span class="aq eg eh as ei ej ek"><a href="https://towardsdatascience.com/our-picks/home?source=post_page-----fcddc4b6fe56----------------------" class="bo bp bq br bs bt bu bv bw bx el em ca cb en eo" rel="noopener">Picks</a></span></li><li class="n o ea eb ec ed"><span class="aq eg eh as ei ej ek"><a href="https://towardsdatascience.com/more/home?source=post_page-----fcddc4b6fe56----------------------" class="bo bp bq br bs bt bu bv bw bx el em ca cb en eo" rel="noopener">More</a></span></li><span class="ea ee ef"></span><li class="n o ea eb ec ed"><span class="aq eg eh as ei ej ek"><a href="https://towardsdatascience.com/contribute/home?source=post_page-----fcddc4b6fe56----------------------" class="bo bp bq br bs bt bu bv bw bx el em ca cb en eo" rel="noopener">Contribute</a></span></li></ul></div></div></div></div></div></div></nav><div class="ep eq r er es"></div><article><section class="et eu ev ew ak ex dd n ey"></section><span class="r"></span><div><div class="ez u fa fb fc fd"></div><div class="ev ew ex bl"><div class="r h g f e"><aside class="ps ez t" style="width: 380.4px;"><div class="pv pw ez qb be ak"><h4 class="aq eg eh as av"><span class="bf pw be bd bc">Top highlight</span></h4></div></aside></div></div><section class="fe ff fg fh fi"><div class="n p"><div class="ac ae af ag ah fj aj ak"><div><div id="f807" class="fk fl co ar fm b fn fo fp fq fr fs ft fu fv fw fx"><h1 class="fm b fn fy fp fz fr ga ft gb fv gc co">Simple Reinforcement Learning: Q-learning</h1></div><div class="gd"><div class="n ge gf gg gh"><div class="o n"><div><a rel="noopener" href="https://towardsdatascience.com/@violante.andre?source=post_page-----fcddc4b6fe56----------------------"><img alt="Andre Violante" class="r dh gi gj" src="./Simple Reinforcement Learning_ Q-learning - Towards Data Science_files/1_hz_UWB_rHwYGpCpd1XAwjQ.png" width="48" height="48"></a></div><div class="gk ak r"><div class="n"><div style="flex:1"><span class="aq b ar as at au r co q"><div class="gl n o gm"><span class="aq eg bj as bd gn bc go gp gq co"><a class="bo bp bq br bs bt bu bv bw bx gr ca cb cc cd" rel="noopener" href="https://towardsdatascience.com/@violante.andre?source=post_page-----fcddc4b6fe56----------------------">Andre Violante</a></span><div class="gs r ap h"><button class="gt cp gu gv gw gx gy gz bx da aq b ar ha eh au db dc dd bf de ca">Follow</button></div></div></span></div></div><span class="aq b ar as at au r av aw"><span class="aq eg bj as bd gn bc go gp gq av"><div><a class="bo bp bq br bs bt bu bv bw bx gr ca cb cc cd" rel="noopener" href="https://towardsdatascience.com/simple-reinforcement-learning-q-learning-fcddc4b6fe56?source=post_page-----fcddc4b6fe56----------------------">Mar 18, 2019</a> <!-- -->·<!-- --> <!-- -->5<!-- --> min read</div></span></span></div></div><div class="n hb hc hd he hf hg hh hi ab"><div class="n o"><div class="hj r ap"><a href="https://medium.com/p/fcddc4b6fe56/share/twitter?source=post_actions_header---------------------------" class="bo bp bq br bs bt bu bv bw bx by bz ca cb cc cd" target="_blank" rel="noopener nofollow"><svg width="29" height="29" class="q"><path d="M22.05 7.54a4.47 4.47 0 0 0-3.3-1.46 4.53 4.53 0 0 0-4.53 4.53c0 .35.04.7.08 1.05A12.9 12.9 0 0 1 5 6.89a5.1 5.1 0 0 0-.65 2.26c.03 1.6.83 2.99 2.02 3.79a4.3 4.3 0 0 1-2.02-.57v.08a4.55 4.55 0 0 0 3.63 4.44c-.4.08-.8.13-1.21.16l-.81-.08a4.54 4.54 0 0 0 4.2 3.15 9.56 9.56 0 0 1-5.66 1.94l-1.05-.08c2 1.27 4.38 2.02 6.94 2.02 8.3 0 12.86-6.9 12.84-12.85.02-.24 0-.43 0-.65a8.68 8.68 0 0 0 2.26-2.34c-.82.38-1.7.62-2.6.72a4.37 4.37 0 0 0 1.95-2.51c-.84.53-1.81.9-2.83 1.13z"></path></svg></a></div><div class="hj r ap"><button class="bo bp bq br bs bt bu bv bw bx by bz ca cb cc cd"><svg width="29" height="29" viewBox="0 0 29 29" fill="none" class="q"><path d="M5 6.36C5 5.61 5.63 5 6.4 5h16.2c.77 0 1.4.61 1.4 1.36v16.28c0 .75-.63 1.36-1.4 1.36H6.4c-.77 0-1.4-.6-1.4-1.36V6.36z"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M10.76 20.9v-8.57H7.89v8.58h2.87zm-1.44-9.75c1 0 1.63-.65 1.63-1.48-.02-.84-.62-1.48-1.6-1.48-.99 0-1.63.64-1.63 1.48 0 .83.62 1.48 1.59 1.48h.01zM12.35 20.9h2.87v-4.79c0-.25.02-.5.1-.7.2-.5.67-1.04 1.46-1.04 1.04 0 1.46.8 1.46 1.95v4.59h2.87v-4.92c0-2.64-1.42-3.87-3.3-3.87-1.55 0-2.23.86-2.61 1.45h.02v-1.24h-2.87c.04.8 0 8.58 0 8.58z" fill="#fff"></path></svg></button></div><div class="hj r ap"><a href="https://medium.com/p/fcddc4b6fe56/share/facebook?source=post_actions_header---------------------------" class="bo bp bq br bs bt bu bv bw bx by bz ca cb cc cd" target="_blank" rel="noopener nofollow"><svg width="29" height="29" class="q"><path d="M23.2 5H5.8a.8.8 0 0 0-.8.8V23.2c0 .44.35.8.8.8h9.3v-7.13h-2.38V13.9h2.38v-2.38c0-2.45 1.55-3.66 3.74-3.66 1.05 0 1.95.08 2.2.11v2.57h-1.5c-1.2 0-1.48.57-1.48 1.4v1.96h2.97l-.6 2.97h-2.37l.05 7.12h5.1a.8.8 0 0 0 .79-.8V5.8a.8.8 0 0 0-.8-.79"></path></svg></a></div><div class="hk r ao"><div><div class="hl"><div><div class="bf" role="tooltip" aria-hidden="true" aria-describedby="1" aria-labelledby="1"><button class="bo bp bq br bs bt bu bv bw bx by bz ca cb cc cd"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div></div></div><figure class="hn ho hp hq hr hs ev ew paragraph-image"><div class="ht hu bl hv ak"><div class="ev ew hm"><div class="ia r bl ib"><div class="ic r"><div class="bk hw ez t u hx ak bd hy hz"><img class="ez t u hx ak id ie cm qa" src="./Simple Reinforcement Learning_ Q-learning - Towards Data Science_files/1_OjizsKNU6_LyM3QW8is0Sg.jpeg" width="4592" height="3448" role="presentation"></div><img class="ny pr ez t u hx ak ig" width="4592" height="3448" role="presentation" src="./Simple Reinforcement Learning_ Q-learning - Towards Data Science_files/1_OjizsKNU6_LyM3QW8is0Sg(1).jpeg"><noscript><img class="ez t u hx ak" src="https://miro.medium.com/max/9184/1*OjizsKNU6_LyM3QW8is0Sg.jpeg" width="4592" height="3448" role="presentation"/></noscript></div></div></div></div><figcaption class="av bj ih ii ij ex ev ew ik il aq eg" data-selectable-paragraph="">Typical Exploring Image for RL - Credit <a href="https://www.instagram.com/mike.shots/" class="bo de im in io ip" target="_blank" rel="noopener nofollow">@mike.shots</a></figcaption></figure><h1 id="7e6f" class="iq ir co ar aq is fn it fp iu iv iw ix iy iz ja jb" data-selectable-paragraph=""><strong class="bu">Introduction</strong></h1><p id="2fe7" class="jc jd co ar je b jf jg jh ji jj jk jl jm jn jo jp fe" data-selectable-paragraph="">One of my favorite algorithms that I learned while taking a reinforcement learning course was q-learning. Probably because it was the easiest for me to understand and code, but also because it seemed to make sense. In this quick post I’ll discuss q-learning and provide the basic background to understanding the algorithm.</p><h1 id="127f" class="iq ir co ar aq is fn it fp iu iv iw ix iy iz ja jb" data-selectable-paragraph=""><strong class="bu">What is q-learning?</strong></h1><p id="1ce0" class="jc jd co ar je b jf jg jh ji jj jk jl jm jn jo jp fe" data-selectable-paragraph="">Q-learning is an off policy reinforcement learning algorithm that seeks to find the best action to take given the current state. It’s considered off-policy because the q-learning function learns from actions that are outside the current policy, like taking random actions, and therefore a policy isn’t needed. More specifically, <mark class="pt pu ls">q-learning seeks to learn a policy that maximizes the total reward.</mark></p><h1 id="e050" class="iq ir co ar aq is fn it fp iu iv iw ix iy iz ja jb" data-selectable-paragraph=""><strong class="bu">What’s ‘Q’?</strong></h1><p id="cc81" class="jc jd co ar je b jf jg jh ji jj jk jl jm jn jo jp fe" data-selectable-paragraph="">The ‘q’ in q-learning stands for quality. Quality in this case represents how useful a given action is in gaining some future reward.</p><h1 id="7464" class="iq ir co ar aq is fn it fp iu iv iw ix iy iz ja jb" data-selectable-paragraph=""><strong class="bu">Create a q-table</strong></h1><p id="2652" class="jc jd co ar je b jf jg jh ji jj jk jl jm jn jo jp fe" data-selectable-paragraph="">When q-learning is performed we create what’s called a <em class="jq">q-table</em> or matrix that follows the shape of <code class="ib jr js jt ju b">[state, action]</code> and we initialize our values to zero. We then update and store our <em class="jq">q-values </em>after an episode. This q-table becomes a reference table for our agent to select the best action based on the q-value.</p><pre class="hn ho hp hq hr jv jw dv"><span id="2ffa" class="jx ir co ar ju b bj jy jz r ka" data-selectable-paragraph="">import numpy as np</span><span id="6b60" class="jx ir co ar ju b bj kb kc kd ke kf jz r ka" data-selectable-paragraph=""># Initialize q-table values to 0</span><span id="d086" class="jx ir co ar ju b bj kb kc kd ke kf jz r ka" data-selectable-paragraph="">Q = np.zeros((state_size, action_size))</span></pre><h1 id="236b" class="iq ir co ar aq is fn it fp iu iv iw ix iy iz ja jb" data-selectable-paragraph=""><strong class="bu">Q-learning and making updates</strong></h1><p id="aa0d" class="jc jd co ar je b jf jg jh ji jj jk jl jm jn jo jp fe" data-selectable-paragraph="">The next step is simply for the agent to interact with the environment and make updates to the state action pairs in our q-table <code class="ib jr js jt ju b">Q[state, action]</code>.</p><p id="0bf9" class="jc jd co ar je b jf kg jh kh jj ki jl kj jn kk jp fe" data-selectable-paragraph=""><em class="jq">Taking Action: Explore or Exploit</em></p><p id="b46f" class="jc jd co ar je b jf kg jh kh jj ki jl kj jn kk jp fe" data-selectable-paragraph="">An agent interacts with the environment in 1 of 2 ways. The first is to use the q-table as a reference and view all possible actions for a given state. The agent then selects the action based on the max value of those actions. This is known as <strong class="je kl"><em class="jq">exploiting</em></strong> since we use the information we have available to us to make a decision.</p><p id="2f0d" class="jc jd co ar je b jf kg jh kh jj ki jl kj jn kk jp fe" data-selectable-paragraph="">The second way to take action is to act randomly. This is called <strong class="je kl"><em class="jq">exploring</em></strong>. Instead of selecting actions based on the max future reward we select an action at random. Acting randomly is important because it allows the agent to explore and discover new states that otherwise may not be selected during the exploitation process. You can balance exploration/exploitation using epsilon (<em class="jq">ε</em>) and setting the value of how often you want to explore vs exploit. Here’s some rough code that will depend on how the state and action space are setup.</p><pre class="hn ho hp hq hr jv jw dv"><span id="e4a9" class="jx ir co ar ju b bj jy jz r ka" data-selectable-paragraph="">import random</span><span id="26ca" class="jx ir co ar ju b bj kb kc kd ke kf jz r ka" data-selectable-paragraph=""># Set the percent you want to explore<br>epsilon = 0.2</span><span id="37ce" class="jx ir co ar ju b bj kb kc kd ke kf jz r ka" data-selectable-paragraph="">if random.uniform(0, 1) &lt; epsilon:<br>    """<br>    Explore: select a random action</span><span id="247c" class="jx ir co ar ju b bj kb kc kd ke kf jz r ka" data-selectable-paragraph="">    """<br>else:<br>    """<br>    Exploit: select the action with max value (future reward)</span><span id="37da" class="jx ir co ar ju b bj kb kc kd ke kf jz r ka" data-selectable-paragraph="">    """</span></pre><p id="ace4" class="jc jd co ar je b jf kg jh kh jj ki jl kj jn kk jp fe" data-selectable-paragraph=""><em class="jq">Updating the q-table</em></p><p id="1389" class="jc jd co ar je b jf kg jh kh jj ki jl kj jn kk jp fe" data-selectable-paragraph="">The updates occur after each step or action and ends when an episode is done. Done in this case means reaching some terminal point by the agent. A terminal state for example can be anything like landing on a checkout page, reaching the end of some game, completing some desired objective, etc. The agent will not learn much after a single episode, but eventually with enough exploring (steps and episodes) it will converge and learn the optimal q-values or q-star (<code class="ib jr js jt ju b">Q∗</code>).</p><p id="33fe" class="jc jd co ar je b jf kg jh kh jj ki jl kj jn kk jp fe" data-selectable-paragraph="">Here are the 3 basic steps:</p><ol class=""><li id="79f0" class="jc jd co ar je b jf kg jh kh jj ki jl kj jn kk jp km kn ko" data-selectable-paragraph="">Agent starts in a state (s1) takes an action (a1) and receives a reward (r1)</li><li id="a229" class="jc jd co ar je b jf kp jh kq jj kr jl ks jn kt jp km kn ko" data-selectable-paragraph="">Agent selects action by referencing Q-table with highest value (max) <strong class="je kl">OR</strong> by random (epsilon, ε)</li><li id="e765" class="jc jd co ar je b jf kp jh kq jj kr jl ks jn kt jp km kn ko" data-selectable-paragraph="">Update q-values</li></ol><p id="e56f" class="jc jd co ar je b jf kg jh kh jj ki jl kj jn kk jp fe" data-selectable-paragraph="">Here is the basic update rule for q-learning:</p><pre class="hn ho hp hq hr jv jw dv"><span id="1bdc" class="jx ir co ar ju b bj jy jz r ka" data-selectable-paragraph=""># Update q values</span><span id="fb32" class="jx ir co ar ju b bj kb kc kd ke kf jz r ka" data-selectable-paragraph="">Q[state, action] = Q[state, action] + lr * (reward + gamma * np.max(Q[new_state, :]) — Q[state, action])</span></pre><p id="5361" class="jc jd co ar je b jf kg jh kh jj ki jl kj jn kk jp fe" data-selectable-paragraph="">In the update above there are a couple variables that we haven’t mentioned yet. Whats happening here is we adjust our q-values based on the difference between the discounted new values and the old values. We discount the new values using gamma and we adjust our step size using learning rate (lr). Below are some references.</p><p id="6906" class="jc jd co ar je b jf kg jh kh jj ki jl kj jn kk jp fe" data-selectable-paragraph=""><strong class="je kl">Learning Rate:</strong> <code class="ib jr js jt ju b">lr</code> or learning rate, often referred to as <em class="jq">alpha </em>or<em class="jq"> </em>α, can simply be defined as how much you accept the new value vs the old value. Above we are taking the difference between new and old and then multiplying that value by the learning rate. This value then gets added to our previous q-value which essentially moves it in the direction of our latest update.</p><p id="4af3" class="jc jd co ar je b jf kg jh kh jj ki jl kj jn kk jp fe" data-selectable-paragraph=""><strong class="je kl">Gamma:</strong> <code class="ib jr js jt ju b">gamma</code> or <em class="jq">γ </em>is a discount factor. It’s used to balance immediate and future reward. From our update rule above you can see that we apply the discount to the future reward. Typically this value can range anywhere from 0.8 to 0.99.</p><p id="49cf" class="jc jd co ar je b jf kg jh kh jj ki jl kj jn kk jp fe" data-selectable-paragraph=""><strong class="je kl">Reward:</strong> <code class="ib jr js jt ju b">reward</code> is the value received after completing a certain action at a given state. A reward can happen at any given time step or only at the terminal time step.</p><p id="6f83" class="jc jd co ar je b jf kg jh kh jj ki jl kj jn kk jp fe" data-selectable-paragraph=""><strong class="je kl">Max:</strong> <code class="ib jr js jt ju b">np.max()</code> uses the numpy library and is taking the maximum of the future reward and applying it to the reward for the current state. What this does is impact the current action by the possible future reward. This is the beauty of q-learning. We’re allocating future reward to current actions to help the agent select the highest return action at any given state.</p><p id="b164" class="jc jd co ar je b jf kg jh kh jj ki jl kj jn kk jp fe" data-selectable-paragraph=""><strong class="je kl">Conclusion</strong></p><p id="6a99" class="jc jd co ar je b jf kg jh kh jj ki jl kj jn kk jp fe" data-selectable-paragraph="">Well that’s it, short and sweet (hopefully). We discussed that q-learning is an off-policy reinforcement learning algorithm. We show the basic update rule for q-learning using some basic python syntax and we reviewed the required inputs to the algorithm. We learned that q-learning uses future rewards to influence the current action given a state and therefore helps the agent select best actions that maximize total reward.</p><p id="1bfd" class="jc jd co ar je b jf kg jh kh jj ki jl kj jn kk jp fe" data-selectable-paragraph="">There is a lot more on q-learning but hopefully this is enough to get you started and interested in learning more. I added several resources below that I found helpful when learning about q-learning. Enjoy!</p><p id="8087" class="jc jd co ar je b jf kg jh kh jj ki jl kj jn kk jp fe" data-selectable-paragraph=""><strong class="je kl">Resources</strong></p><ol class=""><li id="d3f7" class="jc jd co ar je b jf kg jh kh jj ki jl kj jn kk jp km kn ko" data-selectable-paragraph="">Great RL and q-learning example using the <a href="https://www.learndatasci.com/tutorials/reinforcement-q-learning-scratch-python-openai-gym/" class="bo de im in io ip" target="_blank" rel="noopener nofollow">OpenAI Gym taxi </a>environment</li><li id="17fc" class="jc jd co ar je b jf kp jh kq jj kr jl ks jn kt jp km kn ko" data-selectable-paragraph=""><a href="http://www.incompleteideas.net/book/RLbook2018trimmed.pdf" class="bo de im in io ip" target="_blank" rel="noopener nofollow">Reinforcement Learning: An Introduction</a> (free book by Sutton)</li><li id="9313" class="jc jd co ar je b jf kp jh kq jj kr jl ks jn kt jp km kn ko" data-selectable-paragraph="">Quora <a href="https://www.quora.com/How-does-Q-learning-work-1" class="bo de im in io ip" target="_blank" rel="noopener nofollow">Q-learning</a></li><li id="65f1" class="jc jd co ar je b jf kp jh kq jj kr jl ks jn kt jp km kn ko" data-selectable-paragraph="">Wikipedia <a href="https://en.wikipedia.org/wiki/Q-learning" class="bo de im in io ip" target="_blank" rel="noopener nofollow">Q-learning</a></li><li id="3009" class="jc jd co ar je b jf kp jh kq jj kr jl ks jn kt jp km kn ko" data-selectable-paragraph="">David Silver’s <a href="http://www0.cs.ucl.ac.uk/staff/d.silver/web/Teaching.html" class="bo de im in io ip" target="_blank" rel="noopener nofollow">lectures on RL</a></li></ol></div></div></section></div></article><div class="ny fd ku s ak lb kz lc" data-test-id="post-sidebar"><div class="n p"><div class="ac ae af ag ah ai aj ak"><div class="ld n ey"><div class="py"><div class="le lf r"><a href="https://towardsdatascience.com/?source=post_sidebar--------------------------post_sidebar-" class="bo bp bq br bs bt bu bv bw bx by bz ca cb cc cd" rel="noopener"><h2 class="aq is lg as co">Towards Data Science</h2></a><div class="lh li r"><h4 class="aq eg bj as bd lj bc go lk gq av">A Medium publication sharing concepts, ideas, and codes.</h4></div><div class="bf" aria-hidden="true"><button class="cn cp gu gv gw gx gy gz bx da aq b ar as at au db dc dd bf de ca">Follow</button></div></div><div class="ll lm ln n"><div class="n o"><div class="lo r bl"><div class=""><button class="bv lp lq lr ls lt lu lv gv lw gy"><svg width="29" height="29"><g fill-rule="evenodd"><path d="M13.74 1l.76 2.97.76-2.97zM16.82 4.78l1.84-2.56-1.43-.47zM10.38 2.22l1.84 2.56-.41-3.03zM22.38 22.62a5.11 5.11 0 0 1-3.16 1.61l.49-.45c2.88-2.89 3.45-5.98 1.69-9.21l-1.1-1.94-.96-2.02c-.31-.67-.23-1.18.25-1.55a.84.84 0 0 1 .66-.16c.34.05.66.28.88.6l2.85 5.02c1.18 1.97 1.38 5.12-1.6 8.1M9.1 22.1l-5.02-5.02a1 1 0 0 1 .7-1.7 1 1 0 0 1 .72.3l2.6 2.6a.44.44 0 0 0 .63-.62L6.1 15.04l-1.75-1.75a1 1 0 1 1 1.41-1.41l4.15 4.15a.44.44 0 0 0 .63 0 .44.44 0 0 0 0-.62L6.4 11.26l-1.18-1.18a1 1 0 0 1 0-1.4 1.02 1.02 0 0 1 1.41 0l1.18 1.16L11.96 14a.44.44 0 0 0 .62 0 .44.44 0 0 0 0-.63L8.43 9.22a.99.99 0 0 1-.3-.7.99.99 0 0 1 .3-.7 1 1 0 0 1 1.41 0l7 6.98a.44.44 0 0 0 .7-.5l-1.35-2.85c-.31-.68-.23-1.19.25-1.56a.85.85 0 0 1 .66-.16c.34.06.66.28.88.6L20.63 15c1.57 2.88 1.07 5.54-1.55 8.16a5.62 5.62 0 0 1-5.06 1.65 9.35 9.35 0 0 1-4.93-2.72zM13 6.98l2.56 2.56c-.5.6-.56 1.41-.15 2.28l.26.56-4.25-4.25a.98.98 0 0 1-.12-.45 1 1 0 0 1 .29-.7 1.02 1.02 0 0 1 1.41 0zm8.89 2.06c-.38-.56-.9-.92-1.49-1.01a1.74 1.74 0 0 0-1.34.33c-.38.29-.61.65-.71 1.06a2.1 2.1 0 0 0-1.1-.56 1.78 1.78 0 0 0-.99.13l-2.64-2.64a1.88 1.88 0 0 0-2.65 0 1.86 1.86 0 0 0-.48.85 1.89 1.89 0 0 0-2.67-.01 1.87 1.87 0 0 0-.5.9c-.76-.75-2-.75-2.7-.04a1.88 1.88 0 0 0 0 2.66c-.3.12-.61.29-.87.55a1.88 1.88 0 0 0 0 2.66l.62.62a1.88 1.88 0 0 0-.9 3.16l5.01 5.02c1.6 1.6 3.52 2.64 5.4 2.96a7.16 7.16 0 0 0 1.18.1c1.03 0 2-.25 2.9-.7A5.9 5.9 0 0 0 23 23.24c3.34-3.34 3.08-6.93 1.74-9.17l-2.87-5.04z"></path></g></svg></button></div></div><div class="lx r"><div class="ly"><h4 class="aq eg bj as av"><button class="bo bp bq br bs bt bu bv bw bx by bz ca cb cc cd">488 </button></h4></div></div></div></div><div class="lm lz r"></div><div><div class="hl"><div><div class="bf" role="tooltip" aria-hidden="true" aria-describedby="2" aria-labelledby="2"><button class="bo bp bq br bs bt bu bv bw bx by bz ca cb cc cd"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div></div></div></div></div><div class="ny py ku s kv kw kx ky kz la"></div><div><div class="ma hs n ey p"><div class="n p"><div class="ac ae af ag ah fj aj ak"><div class="n mb"></div><div class="n o mb"></div><div class="mc r"><ul class="bv bw"><li class="bf dt md me"><a href="https://towardsdatascience.com/tag/machine-learning" class="mf mg de av r jw mh a b eh">Machine Learning</a></li><li class="bf dt md me"><a href="https://towardsdatascience.com/tag/reinforcement-learning" class="mf mg de av r jw mh a b eh">Reinforcement Learning</a></li><li class="bf dt md me"><a href="https://towardsdatascience.com/tag/q-learning" class="mf mg de av r jw mh a b eh">Q Learning</a></li><li class="bf dt md me"><a href="https://towardsdatascience.com/tag/data-science" class="mf mg de av r jw mh a b eh">Data Science</a></li></ul></div><div class="mi n ge ab"><div class="n o"><div class="ck r bl"><div class=""><div class="c mj dh n o mk bl ml mm mn mo mp mq mr ms mt mu mv mw mx gz"><button class="bv lp lq lr ls lt my lv o ig dh n p mz u hx ez t ak gv lw gy na"><svg width="33" height="33" viewBox="0 0 33 33"><path d="M28.86 17.34l-3.64-6.4c-.3-.43-.71-.73-1.16-.8a1.12 1.12 0 0 0-.9.21c-.62.5-.73 1.18-.32 2.06l1.22 2.6 1.4 2.45c2.23 4.09 1.51 8-2.15 11.66a9.6 9.6 0 0 1-.8.71 6.53 6.53 0 0 0 4.3-2.1c3.82-3.82 3.57-7.87 2.05-10.39zm-6.25 11.08c3.35-3.35 4-6.78 1.98-10.47L21.2 12c-.3-.43-.71-.72-1.16-.8a1.12 1.12 0 0 0-.9.22c-.62.49-.74 1.18-.32 2.06l1.72 3.63a.5.5 0 0 1-.81.57l-8.91-8.9a1.33 1.33 0 0 0-1.89 1.88l5.3 5.3a.5.5 0 0 1-.71.7l-5.3-5.3-1.49-1.49c-.5-.5-1.38-.5-1.88 0a1.34 1.34 0 0 0 0 1.89l1.49 1.5 5.3 5.28a.5.5 0 0 1-.36.86.5.5 0 0 1-.36-.15l-5.29-5.29a1.34 1.34 0 0 0-1.88 0 1.34 1.34 0 0 0 0 1.89l2.23 2.23L9.3 21.4a.5.5 0 0 1-.36.85.5.5 0 0 1-.35-.14l-3.32-3.33a1.33 1.33 0 0 0-1.89 0 1.32 1.32 0 0 0-.39.95c0 .35.14.69.4.94l6.39 6.4c3.53 3.53 8.86 5.3 12.82 1.35zM12.73 9.26l5.68 5.68-.49-1.04c-.52-1.1-.43-2.13.22-2.89l-3.3-3.3a1.34 1.34 0 0 0-1.88 0 1.33 1.33 0 0 0-.4.94c0 .22.07.42.17.61zm14.79 19.18a7.46 7.46 0 0 1-6.41 2.31 7.92 7.92 0 0 1-3.67.9c-3.05 0-6.12-1.63-8.36-3.88l-6.4-6.4A2.31 2.31 0 0 1 2 19.72a2.33 2.33 0 0 1 1.92-2.3l-.87-.87a2.34 2.34 0 0 1 0-3.3 2.33 2.33 0 0 1 1.24-.64l-.14-.14a2.34 2.34 0 0 1 0-3.3 2.39 2.39 0 0 1 3.3 0l.14.14a2.33 2.33 0 0 1 3.95-1.24l.09.09c.09-.42.29-.83.62-1.16a2.34 2.34 0 0 1 3.3 0l3.38 3.39a2.17 2.17 0 0 1 1.27-.17c.54.08 1.03.35 1.45.76.1-.55.41-1.03.9-1.42a2.12 2.12 0 0 1 1.67-.4 2.8 2.8 0 0 1 1.85 1.25l3.65 6.43c1.7 2.83 2.03 7.37-2.2 11.6zM13.22.48l-1.92.89 2.37 2.83-.45-3.72zm8.48.88L19.78.5l-.44 3.7 2.36-2.84zM16.5 3.3L15.48 0h2.04L16.5 3.3z" fill-rule="evenodd"></path></svg></button></div></div></div><div class="lx r"><div class="ly"><h4 class="aq eg bj as co"><button class="bo bp bq br bs bt bu bv bw bx by bz ca cb cc cd">488 claps</button></h4></div></div></div><div class="n o"><div class="hj r ap"><a href="https://medium.com/p/fcddc4b6fe56/share/twitter?source=post_actions_footer---------------------------" class="bo bp bq br bs bt bu bv bw bx by bz ca cb cc cd" target="_blank" rel="noopener nofollow"><svg width="29" height="29" class="q"><path d="M22.05 7.54a4.47 4.47 0 0 0-3.3-1.46 4.53 4.53 0 0 0-4.53 4.53c0 .35.04.7.08 1.05A12.9 12.9 0 0 1 5 6.89a5.1 5.1 0 0 0-.65 2.26c.03 1.6.83 2.99 2.02 3.79a4.3 4.3 0 0 1-2.02-.57v.08a4.55 4.55 0 0 0 3.63 4.44c-.4.08-.8.13-1.21.16l-.81-.08a4.54 4.54 0 0 0 4.2 3.15 9.56 9.56 0 0 1-5.66 1.94l-1.05-.08c2 1.27 4.38 2.02 6.94 2.02 8.3 0 12.86-6.9 12.84-12.85.02-.24 0-.43 0-.65a8.68 8.68 0 0 0 2.26-2.34c-.82.38-1.7.62-2.6.72a4.37 4.37 0 0 0 1.95-2.51c-.84.53-1.81.9-2.83 1.13z"></path></svg></a></div><div class="hj r ap"><button class="bo bp bq br bs bt bu bv bw bx by bz ca cb cc cd"><svg width="29" height="29" viewBox="0 0 29 29" fill="none" class="q"><path d="M5 6.36C5 5.61 5.63 5 6.4 5h16.2c.77 0 1.4.61 1.4 1.36v16.28c0 .75-.63 1.36-1.4 1.36H6.4c-.77 0-1.4-.6-1.4-1.36V6.36z"></path><path fill-rule="evenodd" clip-rule="evenodd" d="M10.76 20.9v-8.57H7.89v8.58h2.87zm-1.44-9.75c1 0 1.63-.65 1.63-1.48-.02-.84-.62-1.48-1.6-1.48-.99 0-1.63.64-1.63 1.48 0 .83.62 1.48 1.59 1.48h.01zM12.35 20.9h2.87v-4.79c0-.25.02-.5.1-.7.2-.5.67-1.04 1.46-1.04 1.04 0 1.46.8 1.46 1.95v4.59h2.87v-4.92c0-2.64-1.42-3.87-3.3-3.87-1.55 0-2.23.86-2.61 1.45h.02v-1.24h-2.87c.04.8 0 8.58 0 8.58z" fill="#fff"></path></svg></button></div><div class="hj r ap"><a href="https://medium.com/p/fcddc4b6fe56/share/facebook?source=post_actions_footer---------------------------" class="bo bp bq br bs bt bu bv bw bx by bz ca cb cc cd" target="_blank" rel="noopener nofollow"><svg width="29" height="29" class="q"><path d="M23.2 5H5.8a.8.8 0 0 0-.8.8V23.2c0 .44.35.8.8.8h9.3v-7.13h-2.38V13.9h2.38v-2.38c0-2.45 1.55-3.66 3.74-3.66 1.05 0 1.95.08 2.2.11v2.57h-1.5c-1.2 0-1.48.57-1.48 1.4v1.96h2.97l-.6 2.97h-2.37l.05 7.12h5.1a.8.8 0 0 0 .79-.8V5.8a.8.8 0 0 0-.8-.79"></path></svg></a></div><div class="hj r ap"><div><div class="hl"><div><div class="bf" role="tooltip" aria-hidden="true" aria-describedby="3" aria-labelledby="3"><button class="bo bp bq br bs bt bu bv bw bx by bz ca cb cc cd"><svg width="25" height="25" viewBox="0 0 25 25"><path d="M19 6a2 2 0 0 0-2-2H8a2 2 0 0 0-2 2v14.66h.01c.01.1.05.2.12.28a.5.5 0 0 0 .7.03l5.67-4.12 5.66 4.13a.5.5 0 0 0 .71-.03.5.5 0 0 0 .12-.29H19V6zm-6.84 9.97L7 19.64V6a1 1 0 0 1 1-1h9a1 1 0 0 1 1 1v13.64l-5.16-3.67a.49.49 0 0 0-.68 0z" fill-rule="evenodd"></path></svg></button></div></div></div></div></div><div class="bf" aria-hidden="true"><div class="bf" aria-hidden="true"><div class="r ap"><button class="bo bp bq br bs bt bu bv bw bx by bz ca cb cc cd"><svg width="25" height="25" viewBox="-480.5 272.5 21 21" class="q"><path d="M-463 284.6c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5zm-7-.9c.9 0 1.6-.7 1.6-1.6s-.7-1.6-1.6-1.6-1.6.7-1.6 1.6.7 1.6 1.6 1.6zm0 .9c-1.4 0-2.5-1.1-2.5-2.5s1.1-2.5 2.5-2.5 2.5 1.1 2.5 2.5-1.1 2.5-2.5 2.5z"></path></svg></button></div></div></div></div></div><div class="nb nc nd mc r ab"><div class="ne nf r bl"><span class="r ng an nh"><div class="r ez ni nj"><a rel="noopener" href="https://towardsdatascience.com/@violante.andre?source=follow_footer--------------------------follow_footer-"><img alt="Andre Violante" class="r dh dz nk" src="./Simple Reinforcement Learning_ Q-learning - Towards Data Science_files/1_hz_UWB_rHwYGpCpd1XAwjQ(1).png" width="80" height="80"></a></div><span class="r"><div class="nl r nm"><p class="aq eg eh as av ej nn">Written by</p></div><div class="nl no n nm"><div class="ak n o ge"><h2 class="aq is np nq co"><a class="bo bp bq br bs bt bu bv bw bx by bz ca cb cc cd" rel="noopener" href="https://towardsdatascience.com/@violante.andre?source=follow_footer--------------------------follow_footer-">Andre Violante</a></h2><div class="r g"><button class="cn cp gu gv gw gx gy gz bx da aq b ar as at au db dc dd bf de ca">Follow</button></div></div></div></span></span><div class="nl nr r nm dm"><div class="ns r"><h4 class="aq eg lg nt av">data scientist @IBM. lifelong learner. family. fitness. be: grateful, true, respectful, humble.</h4></div><div class="ci nu dm"><button class="cn cp gu gv gw gx gy gz bx da aq b ar as at au db dc dd bf de ca">Follow</button></div></div></div><div class="nb r"></div><div class="ne nf r bl"><span class="r ng an nh"><div class="r ez ni nj"><a href="https://towardsdatascience.com/?source=follow_footer--------------------------follow_footer-" rel="noopener"><img alt="Towards Data Science" class="da nk dz" src="./Simple Reinforcement Learning_ Q-learning - Towards Data Science_files/1_hVxgUA6kP-PgL5TJjuyePg.png" width="80" height="80"></a></div><span class="r"><div class="nl no n nm"><div class="ak n o ge"><h2 class="aq is np nq co"><a href="https://towardsdatascience.com/?source=follow_footer--------------------------follow_footer-" class="bo bp bq br bs bt bu bv bw bx by bz ca cb cc cd" rel="noopener">Towards Data Science</a></h2><div class="r g"><div class="bf" aria-hidden="true"><button class="cn cp gu gv gw gx gy gz bx da aq b ar as at au db dc dd bf de ca">Follow</button></div></div></div></div></span></span><div class="nl nv r nm dm"><div class="ns r"><h4 class="aq eg lg nt av">A Medium publication sharing concepts, ideas, and codes.</h4></div><div class="ci nu dm"><div class="bf" aria-hidden="true"><button class="cn cp gu gv gw gx gy gz bx da aq b ar as at au db dc dd bf de ca">Follow</button></div></div></div></div></div><div class="nw nc r ab"><a href="https://medium.com/p/fcddc4b6fe56/responses/show?source=follow_footer--------------------------follow_footer-" class="bo bp bq br bs bt bu bv bw bx by bz ca cb cc cd" rel="noopener"><span class="nx ny ls"><div class="jv nz da r ij dm"><span class="gu">See responses (2)</span></div></span></a></div></div></div><div class="oa r ob ab"><div class="n p"><div class="ac ae af ag ah ai aj ak"></div></div></div></div></div><div class="oc r od oe"><section class="ev ew ak dd r of og oh oi oj ok ol om on oo op oq or os ot"><div class="ou ov ne n ge g"><div class="ow n ge"><div class="ox r oy"><div class="oz r"><a href="https://medium.com/about?autoplay=1&amp;source=post_page-----fcddc4b6fe56----------------------" class="bo bp bq br bs bt bu bv bw bx pa pb ca cb pc pd" rel="noopener"><h4 class="pe pf pg aq is ar nt ph pi r">Discover <!-- -->Medium</h4></a></div><span class="aq b ar as at au r pj pk">Welcome to a place where words matter. On <!-- -->Medium<!-- -->, smart voices and original ideas take center stage - with no ads in sight.<!-- --> <a href="https://medium.com/about?autoplay=1&amp;source=post_page-----fcddc4b6fe56----------------------" class="bo bp bq br bs bt bu bv bw bx ca cb pc pd pl" rel="noopener">Watch</a></span></div><div class="ox r oy"><div class="pm r"><a href="https://medium.com/topics?source=post_page-----fcddc4b6fe56----------------------" class="bo bp bq br bs bt bu bv bw bx pa pb ca cb pc pd" rel="noopener"><h4 class="pe pf pg aq is ar nt ph pi r">Make <!-- -->Medium<!-- --> yours</h4></a></div><span class="aq b ar as at au r pj pk">Follow all the topics you care about, and we’ll deliver the best stories for you to your homepage and inbox.<!-- --> <a href="https://medium.com/topics?source=post_page-----fcddc4b6fe56----------------------" class="bo bp bq br bs bt bu bv bw bx ca cb pc pd pl" rel="noopener">Explore</a></span></div><div class="ox r oy"><div class="oz r"><a href="https://medium.com/membership?source=post_page-----fcddc4b6fe56----------------------" class="bo bp bq br bs bt bu bv bw bx pa pb ca cb pc pd" rel="noopener"><h4 class="pe pf pg aq is ar nt ph pi r">Become a member</h4></a></div><span class="aq b ar as at au r pj pk">Get unlimited access to the best stories on <!-- -->Medium<!-- --> — and support writers while you’re at it. Just $5/month.<!-- --> <a href="https://medium.com/membership?source=post_page-----fcddc4b6fe56----------------------" class="bo bp bq br bs bt bu bv bw bx ca cb pc pd pl" rel="noopener">Upgrade</a></span></div></div></div><div class="n o ge"><a href="https://medium.com/?source=post_page-----fcddc4b6fe56----------------------" class="bo bp bq br bs bt bu bv bw bx pa pb ca cb pc pd" rel="noopener"><svg height="22" width="112" viewBox="0 0 111.5 22" class="pf"><path d="M56.3 19.5c0 .4 0 .5.3.7l1.5 1.4v.1h-6.5V19c-.7 1.8-2.4 3-4.3 3-3.3 0-5.8-2.6-5.8-7.5 0-4.5 2.6-7.6 6.3-7.6 1.6-.1 3.1.8 3.8 2.4V3.2c0-.3-.1-.6-.3-.7l-1.4-1.4V1l6.5-.8v19.3zm-4.8-.8V9.5c-.5-.6-1.2-.9-1.9-.9-1.6 0-3.1 1.4-3.1 5.7 0 4 1.3 5.4 3 5.4.8.1 1.6-.3 2-1zm9.1 3.1V9.4c0-.3-.1-.6-.3-.7l-1.4-1.5v-.1h6.5v12.5c0 .4 0 .5.3.7l1.4 1.4v.1h-6.5zm-.2-19.2C60.4 1.2 61.5 0 63 0c1.4 0 2.6 1.2 2.6 2.6S64.4 5.3 63 5.3a2.6 2.6 0 0 1-2.6-2.7zm22.5 16.9c0 .4 0 .5.3.7l1.5 1.4v.1h-6.5v-3.2c-.6 2-2.4 3.4-4.5 3.4-2.9 0-4.4-2.1-4.4-6.2 0-1.9 0-4.1.1-6.5 0-.3-.1-.5-.3-.7L67.7 7v.1H74v8c0 2.6.4 4.4 2 4.4.9-.1 1.7-.6 2.1-1.3V9.5c0-.3-.1-.6-.3-.7l-1.4-1.5v-.2h6.5v12.4zm22 2.3c0-.5.1-6.5.1-7.9 0-2.6-.4-4.5-2.2-4.5-.9 0-1.8.5-2.3 1.3.2.8.3 1.7.3 2.5 0 1.8-.1 4.2-.1 6.5 0 .3.1.5.3.7l1.5 1.4v.1H96c0-.4.1-6.5.1-7.9 0-2.7-.4-4.5-2.2-4.5-.9 0-1.7.5-2.2 1.3v9c0 .4 0 .5.3.7l1.4 1.4v.1h-6.5V9.5c0-.3-.1-.6-.3-.7l-1.4-1.5v-.2h6.5v3.1a4.6 4.6 0 0 1 4.6-3.4c2.2 0 3.6 1.2 4.2 3.5.7-2.1 2.7-3.6 4.9-3.5 2.9 0 4.5 2.2 4.5 6.2 0 1.9-.1 4.2-.1 6.5-.1.3.1.6.3.7l1.4 1.4v.1h-6.6zm-81.4-2l1.9 1.9v.1h-9.8v-.1l2-1.9c.2-.2.3-.4.3-.7V7.3c0-.5 0-1.2.1-1.8L11.4 22h-.1L4.5 6.8c-.1-.4-.2-.4-.3-.6v10c-.1.7 0 1.3.3 1.9l2.7 3.6v.1H0v-.1L2.7 18c.3-.6.4-1.3.3-1.9v-11c0-.5-.1-1.1-.5-1.5L.7 1.1V1h7l5.8 12.9L18.6 1h6.8v.1l-1.9 2.2c-.2.2-.3.5-.3.7v15.2c0 .2.1.5.3.6zm7.6-5.9c0 3.8 1.9 5.3 4.2 5.3 1.9.1 3.6-1 4.4-2.7h.1c-.8 3.7-3.1 5.5-6.5 5.5-3.7 0-7.2-2.2-7.2-7.4 0-5.5 3.5-7.6 7.3-7.6 3.1 0 6.4 1.5 6.4 6.2v.8h-8.7zm0-.8h4.3v-.8c0-3.9-.8-4.9-2-4.9-1.4.1-2.3 1.6-2.3 5.7z"></path></svg></a><span class="aq b ar as at au r pj pk"><div class="pn po n ge pp an"><a href="https://medium.com/about?autoplay=1&amp;source=post_page-----fcddc4b6fe56----------------------" class="bo bp bq br bs bt bu bv bw bx gr ca cb pc pd" rel="noopener">About</a><a href="https://help.medium.com/?source=post_page-----fcddc4b6fe56----------------------" class="bo bp bq br bs bt bu bv bw bx gr ca cb pc pd" rel="noopener">Help</a><a href="https://medium.com/policy/9db0094a1e0f?source=post_page-----fcddc4b6fe56----------------------" class="bo bp bq br bs bt bu bv bw bx gr ca cb pc pd" rel="noopener">Legal</a></div></span></div></section></div></div></div><script src="./Simple Reinforcement Learning_ Q-learning - Towards Data Science_files/16180790160.js.download"></script><iframe src="./Simple Reinforcement Learning_ Q-learning - Towards Data Science_files/a16180790160.html" hidden="" aria-hidden="true" tabindex="-1" title="Optimizely Internal Frame" height="0" width="0" style="display: none;"></iframe><script>window.__BUILD_ID__ = "development"</script><script>window.__GRAPHQL_URI__ = "https://towardsdatascience.com/_/graphql"</script><script>window.__PRELOADED_STATE__ = {"config":{"nodeEnv":"production","version":"master-20200228-201623-8129311683","productName":"Medium","publicUrl":"https:\u002F\u002Fcdn-client.medium.com\u002Flite","authDomain":"medium.com","authGoogleClientId":"216296035834-k1k6qe060s2tp2a2jam4ljdcms00sttg.apps.googleusercontent.com","favicon":"production","glyphUrl":"https:\u002F\u002Fglyph.medium.com","branchKey":"key_live_ofxXr2qTrrU9NqURK8ZwEhknBxiI6KBm","lightStep":{"name":"lite-web","host":"collector-medium.lightstep.com","token":"ce5be895bef60919541332990ac9fef2","appVersion":"master-20200228-201623-8129311683"},"algolia":{"appId":"MQ57UUUQZ2","apiKeySearch":"394474ced050e3911ae2249ecc774921","indexPrefix":"medium_","host":"-dsn.algolia.net"},"recaptchaKey":"6Lfc37IUAAAAAKGGtC6rLS13R1Hrw_BqADfS1LRk","recaptcha3Key":"6Lf8R9wUAAAAABMI_85Wb8melS7Zj6ziuf99Yot5","sentry":{"dsn":"https:\u002F\u002F589e367c28ca47b195ce200d1507d18b@sentry.io\u002F1423575","environment":"production"},"isAmp":false,"googleAnalyticsCode":"UA-24232453-2","signInWallCustomDomainCollectionIds":["3a8144eabfe3","336d898217ee","61061eb0c96b","138adf9c44c","819cc2aaeee0"],"mediumOwnedAndOperatedCollectionIds":["544c7006046e","bcc38c8f6edf","444d13b52878","8d6b8a439e32","92d2092dc598","1285ba81cada","cb8577c9149e","8ccfed20cbb2","ae2a65f35510","3f6ecf56618","7b6769f2748b","fc8964313712","ef8e90590e66","191186aaafa0","d944778ce714","bdc4052bbdba","88d9857e584e"],"tierOneDomains":["medium.com","thebolditalic.com","arcdigital.media","towardsdatascience.com","uxdesign.cc","codeburst.io","psiloveyou.xyz","writingcooperative.com","entrepreneurshandbook.co","prototypr.io","betterhumans.coach.me","theascent.pub"],"internalLinksPostIds":["0000","0001","0002","0003"],"defaultImages":{"avatar":{"imageId":"1*dmbNkD5D-u45r44go_cf0g.png","height":150,"width":150},"orgLogo":{"imageId":"1*OMF3fSqH8t4xBJ9-6oZDZw.png","height":106,"width":545},"postLogo":{"imageId":"1*3sela1OADrJr7dJk_CXaEQ.png","height":810,"width":1440}},"performanceTags":[]},"debug":{"requestId":"92f882ba-b656-46fc-9092-14f2196c6551","originalSpanCarrier":{"ot-tracer-spanid":"4906c46d4d3c6b98","ot-tracer-traceid":"2c1d60c5231a606a","ot-tracer-sampled":"true"}},"session":{"user":{"id":"e877de80fba3"},"xsrf":"KluSTzGVe0lk"},"stats":{"itemCount":0,"sending":false,"timeout":null,"backup":{}},"navigation":{"branch":{"show":null,"hasRendered":null,"blockedByCTA":true},"hideGoogleOneTap":false,"hasRenderedGoogleOneTap":null,"currentLocation":"https:\u002F\u002Ftowardsdatascience.com\u002Fsimple-reinforcement-learning-q-learning-fcddc4b6fe56","host":"towardsdatascience.com","hostname":"towardsdatascience.com","referrer":"https:\u002F\u002Fwww.google.com\u002F","susiModal":{"step":null,"operation":"register","reportEventInfo":{"eventName":"","data":{}}},"postRead":false},"client":{"isBot":false,"isEu":false,"isLinkedin":false,"isNativeMedium":false,"isCustomDomain":true},"multiVote":{"clapsPerPost":{}},"metadata":{"faviconImageId":null}}</script><script>window.__APOLLO_STATE__ = {"ROOT_QUERY.variantFlags.0":{"name":"add_friction_to_signup","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.0.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.0.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.1":{"name":"allow_access","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.1.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.1.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.2":{"name":"allow_signup","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.2.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.2.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.3":{"name":"allow_test_auth","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.3.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.3.valueType":{"__typename":"VariantFlagString","value":"disallow"},"ROOT_QUERY.variantFlags.4":{"name":"assign_default_topic_to_posts","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.4.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.4.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.5":{"name":"available_annual_plan","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.5.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.5.valueType":{"__typename":"VariantFlagString","value":"2c754bcc2995"},"ROOT_QUERY.variantFlags.6":{"name":"available_monthly_plan","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.6.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.6.valueType":{"__typename":"VariantFlagString","value":"60e220181034"},"ROOT_QUERY.variantFlags.7":{"name":"branch_seo_metadata","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.7.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.7.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.8":{"name":"browsable_stream_config_bucket","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.8.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.8.valueType":{"__typename":"VariantFlagString","value":"curated-topics"},"ROOT_QUERY.variantFlags.9":{"name":"disable_android_subscription_activity_carousel","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.9.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.9.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.10":{"name":"disable_go_social_jubilee","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.10.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.10.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.11":{"name":"disable_gosocial_followers_that_you_follow","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.11.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.11.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.12":{"name":"disable_ios_resume_reading_toast","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.12.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.12.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.13":{"name":"disable_ios_subscription_activity_carousel","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.13.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.13.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.14":{"name":"disable_mobile_featured_chunk","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.14.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.14.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.15":{"name":"disable_post_recommended_from_friends_provider","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.15.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.15.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.16":{"name":"enable_android_local_currency","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.16.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.16.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.17":{"name":"enable_annual_renewal_reminder_email","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.17.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.17.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.18":{"name":"enable_app_flirty_thirty","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.18.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.18.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.19":{"name":"enable_auto_tier","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.19.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.19.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.20":{"name":"enable_automated_mission_control_triggers","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.20.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.20.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.21":{"name":"enable_branch_io","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.21.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.21.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.22":{"name":"enable_branding","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.22.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.22.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.23":{"name":"enable_branding_fonts","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.23.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.23.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.24":{"name":"enable_curation_priority_queue_experiment","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.24.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.24.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.25":{"name":"enable_daily_read_digest_promo","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.25.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.25.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.26":{"name":"enable_dedicated_series_tab_api_ios","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.26.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.26.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.27":{"name":"enable_different_grid","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.27.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.27.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.28":{"name":"enable_disregard_trunc_state_for_footer","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.28.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.28.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.29":{"name":"enable_edit_alt_text","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.29.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.29.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.30":{"name":"enable_email_sign_in_captcha","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.30.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.30.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.31":{"name":"enable_embedding_based_diversification","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.31.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.31.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.32":{"name":"enable_expanded_feature_chunk_pool","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.32.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.32.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.33":{"name":"enable_filter_by_resend_rules","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.33.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.33.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.34":{"name":"enable_first_name_on_paywall","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.34.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.34.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.35":{"name":"enable_google_one_tap","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.35.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.35.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.36":{"name":"enable_grace_period_google_play","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.36.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.36.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.37":{"name":"enable_ios_post_stats","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.37.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.37.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.38":{"name":"enable_janky_spam_rules","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.38.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.38.valueType":{"__typename":"VariantFlagString","value":"users,posts"},"ROOT_QUERY.variantFlags.39":{"name":"enable_json_logs_trained_ranker","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.39.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.39.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.40":{"name":"enable_kafka_events","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.40.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.40.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.41":{"name":"enable_kbfd_rex","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.41.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.41.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.42":{"name":"enable_kbfd_rex_app_highlights","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.42.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.42.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.43":{"name":"enable_kbfd_rex_daily_digest","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.43.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.43.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.44":{"name":"enable_lite_notifications","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.44.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.44.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.45":{"name":"enable_lite_post","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.45.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.45.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.46":{"name":"enable_lite_post_cd","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.46.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.46.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.47":{"name":"enable_lite_post_highlights","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.47.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.47.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.48":{"name":"enable_lite_post_highlights_view_only","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.48.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.48.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.49":{"name":"enable_lite_profile","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.49.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.49.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.50":{"name":"enable_lite_pub_header_menu","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.50.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.50.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.51":{"name":"enable_lite_server_upstream_deadlines","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.51.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.51.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.52":{"name":"enable_lite_stories","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.52.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.52.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.53":{"name":"enable_lite_topics","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.53.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.53.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.54":{"name":"enable_lite_unread_notification_count_mutation","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.54.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.54.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.55":{"name":"enable_lo_meter_swap","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.55.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.55.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.56":{"name":"enable_logged_out_homepage_signup","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.56.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.56.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.57":{"name":"enable_login_code_flow","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.57.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.57.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.58":{"name":"enable_marketing_emails","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.58.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.58.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.59":{"name":"enable_media_resource_try_catch","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.59.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.59.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.60":{"name":"enable_membership_remove_section_a","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.60.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.60.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.61":{"name":"enable_minimal_meter_experience","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.61.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.61.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.62":{"name":"enable_miro_on_kubernetes","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.62.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.62.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.63":{"name":"enable_mk_branch_cleanup","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.63.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.63.valueType":{"__typename":"VariantFlagString","value":"app-button"},"ROOT_QUERY.variantFlags.64":{"name":"enable_ml_rank_modules","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.64.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.64.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.65":{"name":"enable_more_branch_data","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.65.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.65.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.66":{"name":"enable_new_collaborative_filtering_data","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.66.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.66.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.67":{"name":"enable_new_pub_modules","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.67.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.67.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.68":{"name":"enable_new_suspended_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.68.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.68.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.69":{"name":"enable_new_three_dot_menu","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.69.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.69.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.70":{"name":"enable_optimizely","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.70.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.70.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.71":{"name":"enable_parsely","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.71.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.71.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.72":{"name":"enable_patronus_on_kubernetes","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.72.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.72.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.73":{"name":"enable_popularity_feature","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.73.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.73.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.74":{"name":"enable_post_import","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.74.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.74.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.75":{"name":"enable_post_seo_settings_screen","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.75.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.75.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.76":{"name":"enable_post_settings_screen","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.76.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.76.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.77":{"name":"enable_primary_topic_for_mobile","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.77.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.77.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.78":{"name":"enable_rito_upstream_deadlines","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.78.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.78.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.79":{"name":"enable_rtr_channel","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.79.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.79.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.80":{"name":"enable_save_to_medium","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.80.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.80.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.81":{"name":"enable_sign_up_with_email","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.81.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.81.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.82":{"name":"enable_suggest_account","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.82.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.82.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.83":{"name":"enable_suggest_account_li","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.83.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.83.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.84":{"name":"enable_tick_landing_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.84.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.84.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.85":{"name":"enable_ticks_digest_promo","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.85.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.85.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.86":{"name":"enable_tipalti_onboarding","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.86.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.86.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.87":{"name":"enable_topic_lifecycle_email","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.87.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.87.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.88":{"name":"enable_tribute_landing_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.88.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.88.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.89":{"name":"enable_trumpland_landing_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.89.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.89.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.90":{"name":"filter_low_scoring_users","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.90.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.90.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.91":{"name":"glyph_font_set","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.91.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.91.valueType":{"__typename":"VariantFlagString","value":"m2"},"ROOT_QUERY.variantFlags.92":{"name":"google_sign_in_android","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.92.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.92.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.93":{"name":"iceland_home_page_loadtest","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.93.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.93.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.94":{"name":"is_in_recs_holdout_q1_2020","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.94.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.94.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.95":{"name":"is_not_medium_subscriber","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.95.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.95.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.96":{"name":"new_transition_page","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.96.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.96.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.97":{"name":"pardon_the_interruption_4","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.97.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.97.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.98":{"name":"pub_sidebar","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.98.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.98.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.99":{"name":"rank_model","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.99.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.99.valueType":{"__typename":"VariantFlagString","value":"default"},"ROOT_QUERY.variantFlags.100":{"name":"redis_read_write_splitting","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.100.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.100.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.101":{"name":"share_post_linkedin","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.101.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.101.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY.variantFlags.102":{"name":"signin_services","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.102.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.102.valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"},"ROOT_QUERY.variantFlags.103":{"name":"signup_services","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.103.valueType","typename":"VariantFlagString"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.103.valueType":{"__typename":"VariantFlagString","value":"twitter,facebook,google,email,google-fastidv,google-one-tap,apple"},"ROOT_QUERY.variantFlags.104":{"name":"use_new_admin_topic_backend","valueType":{"type":"id","generated":true,"id":"$ROOT_QUERY.variantFlags.104.valueType","typename":"VariantFlagBoolean"},"__typename":"VariantFlag"},"$ROOT_QUERY.variantFlags.104.valueType":{"__typename":"VariantFlagBoolean","value":true},"ROOT_QUERY":{"variantFlags":[{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.0","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.1","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.2","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.3","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.4","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.5","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.6","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.7","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.8","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.9","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.10","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.11","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.12","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.13","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.14","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.15","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.16","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.17","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.18","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.19","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.20","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.21","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.22","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.23","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.24","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.25","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.26","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.27","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.28","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.29","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.30","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.31","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.32","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.33","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.34","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.35","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.36","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.37","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.38","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.39","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.40","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.41","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.42","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.43","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.44","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.45","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.46","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.47","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.48","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.49","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.50","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.51","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.52","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.53","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.54","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.55","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.56","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.57","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.58","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.59","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.60","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.61","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.62","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.63","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.64","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.65","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.66","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.67","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.68","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.69","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.70","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.71","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.72","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.73","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.74","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.75","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.76","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.77","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.78","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.79","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.80","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.81","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.82","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.83","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.84","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.85","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.86","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.87","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.88","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.89","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.90","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.91","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.92","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.93","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.94","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.95","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.96","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.97","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.98","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.99","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.100","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.101","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.102","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.103","typename":"VariantFlag"},{"type":"id","generated":true,"id":"ROOT_QUERY.variantFlags.104","typename":"VariantFlag"}],"viewer":{"type":"id","generated":false,"id":"User:e877de80fba3","typename":"User"},"meterPost({\"postId\":\"fcddc4b6fe56\",\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}})":{"type":"id","generated":false,"id":"MeteringInfo:singleton","typename":"MeteringInfo"},"postResult({\"id\":\"fcddc4b6fe56\"})":{"type":"id","generated":false,"id":"Post:fcddc4b6fe56","typename":"Post"}},"User:e877de80fba3":{"id":"e877de80fba3","username":"hayderendoprez","name":"Hayder Endo Pérez","imageId":"0*Q-PdbCU7WM5apRrk.","mediumMemberAt":0,"hasPastMemberships":false,"isPartnerProgramEnrolled":false,"email":"hayder9701@gmail.com","unverifiedEmail":"","createdAt":1520957959178,"__typename":"User"},"MeteringInfo:singleton":{"__typename":"MeteringInfo","postIds":{"type":"json","json":[]},"maxUnlockCount":3,"unlocksRemaining":3},"Post:fcddc4b6fe56":{"__typename":"Post","visibility":"PUBLIC","latestPublishedVersion":"2ee44278ac49","collection":{"type":"id","generated":false,"id":"Collection:7f60cf5620c9","typename":"Collection"},"id":"fcddc4b6fe56","creator":{"type":"id","generated":false,"id":"User:54f2f2975136","typename":"User"},"isLocked":false,"lockedSource":"LOCKED_POST_SOURCE_NONE","sequence":null,"mediumUrl":"https:\u002F\u002Ftowardsdatascience.com\u002Fsimple-reinforcement-learning-q-learning-fcddc4b6fe56","canonicalUrl":"","content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}})":{"type":"id","generated":true,"id":"$Post:fcddc4b6fe56.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}})","typename":"PostContent"},"firstPublishedAt":1552941664323,"isPublished":true,"layerCake":0,"primaryTopic":null,"title":"Simple Reinforcement Learning: Q-learning","isLimitedState":false,"pendingCollection":null,"shareKey":null,"statusForCollection":"APPROVED","readingTime":4.060377358490566,"readingList":"READING_LIST_NONE","allowResponses":true,"clapCount":488,"viewerClapCount":null,"license":"ALL_RIGHTS_RESERVED","tags":[{"type":"id","generated":false,"id":"Tag:machine-learning","typename":"Tag"},{"type":"id","generated":false,"id":"Tag:reinforcement-learning","typename":"Tag"},{"type":"id","generated":false,"id":"Tag:q-learning","typename":"Tag"},{"type":"id","generated":false,"id":"Tag:data-science","typename":"Tag"}],"voterCount":107,"recommenders":[],"responses":{"type":"id","generated":true,"id":"$Post:fcddc4b6fe56.responses","typename":"StreamConnection"},"responsesCount":2,"collaborators":[],"translationSourcePost":null,"newsletterId":"","inResponseToPostResult":null,"inResponseToMediaResource":null,"curationEligibleAt":0,"isDistributionAlertDismissed":false,"audioVersionUrl":"","seoTitle":"","socialTitle":"","socialDek":"","metaDescription":"","latestPublishedAt":1562005540339,"previewContent":{"type":"id","generated":true,"id":"$Post:fcddc4b6fe56.previewContent","typename":"PreviewContent"},"previewImage":{"type":"id","generated":false,"id":"ImageMetadata:1*OjizsKNU6_LyM3QW8is0Sg.jpeg","typename":"ImageMetadata"},"updatedAt":1562005540652,"topics":[],"seoDescription":"","isSuspended":false},"Collection:7f60cf5620c9":{"id":"7f60cf5620c9","domain":"towardsdatascience.com","slug":"towards-data-science","__typename":"Collection","auroraAlphaEnabled":false,"googleAnalyticsId":"UA-19707169-24","customStyleSheet":null,"colorBehavior":"ACCENT_COLOR_AND_FILL_BACKGROUND","name":"Towards Data Science","logo":{"type":"id","generated":false,"id":"ImageMetadata:1*mG6i4Bh_LgixUYXJgQpYsg@2x.png","typename":"ImageMetadata"},"avatar":{"type":"id","generated":false,"id":"ImageMetadata:1*hVxgUA6kP-PgL5TJjuyePg.png","typename":"ImageMetadata"},"isEnrolledInHightower":false,"creator":{"type":"id","generated":false,"id":"User:895063a310f4","typename":"User"},"viewerIsEditor":false,"navItems":[{"type":"id","generated":true,"id":"Collection:7f60cf5620c9.navItems.0","typename":"NavItem"},{"type":"id","generated":true,"id":"Collection:7f60cf5620c9.navItems.1","typename":"NavItem"},{"type":"id","generated":true,"id":"Collection:7f60cf5620c9.navItems.2","typename":"NavItem"},{"type":"id","generated":true,"id":"Collection:7f60cf5620c9.navItems.3","typename":"NavItem"},{"type":"id","generated":true,"id":"Collection:7f60cf5620c9.navItems.4","typename":"NavItem"},{"type":"id","generated":true,"id":"Collection:7f60cf5620c9.navItems.5","typename":"NavItem"},{"type":"id","generated":true,"id":"Collection:7f60cf5620c9.navItems.6","typename":"NavItem"},{"type":"id","generated":true,"id":"Collection:7f60cf5620c9.navItems.7","typename":"NavItem"}],"colorPalette":{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette","typename":"ColorPalette"},"viewerCanEditOwnPosts":false,"viewerCanEditPosts":false,"viewerIsMuting":false,"description":"A Medium publication sharing concepts, ideas, and codes.","viewerIsFollowing":false,"viewerIsSubscribedToLetters":false,"isUserSubscribedToCollectionEmails":false,"ampEnabled":false,"twitterUsername":"TDataScience","facebookPageId":null,"favicon":{"type":"id","generated":false,"id":"ImageMetadata:1*ChFMdf--f5jbm-AYv6VdYA@2x.png","typename":"ImageMetadata"}},"User:54f2f2975136":{"id":"54f2f2975136","__typename":"User","isSuspended":false,"allowNotes":true,"name":"Andre Violante","isFollowing":false,"username":"violante.andre","bio":"data scientist @IBM. lifelong learner. family. fitness. be: grateful, true, respectful, humble.","imageId":"1*hz_UWB_rHwYGpCpd1XAwjQ.png","mediumMemberAt":0,"isBlocking":false,"isMuting":false,"isPartnerProgramEnrolled":false,"twitterScreenName":""},"ImageMetadata:1*mG6i4Bh_LgixUYXJgQpYsg@2x.png":{"id":"1*mG6i4Bh_LgixUYXJgQpYsg@2x.png","originalWidth":337,"originalHeight":122,"__typename":"ImageMetadata"},"ImageMetadata:1*hVxgUA6kP-PgL5TJjuyePg.png":{"id":"1*hVxgUA6kP-PgL5TJjuyePg.png","__typename":"ImageMetadata"},"User:895063a310f4":{"id":"895063a310f4","__typename":"User"},"Collection:7f60cf5620c9.navItems.0":{"title":"Data Science","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fdata-science\u002Fhome","type":"TOPIC_PAGE","__typename":"NavItem"},"Collection:7f60cf5620c9.navItems.1":{"title":"Machine Learning","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fmachine-learning\u002Fhome","type":"TOPIC_PAGE","__typename":"NavItem"},"Collection:7f60cf5620c9.navItems.2":{"title":"Programming","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fprogramming\u002Fhome","type":"TOPIC_PAGE","__typename":"NavItem"},"Collection:7f60cf5620c9.navItems.3":{"title":"Visualization","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fdata-visualization\u002Fhome","type":"TOPIC_PAGE","__typename":"NavItem"},"Collection:7f60cf5620c9.navItems.4":{"title":"AI","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fartificial-intelligence\u002Fhome","type":"TOPIC_PAGE","__typename":"NavItem"},"Collection:7f60cf5620c9.navItems.5":{"title":"Picks","url":"https:\u002F\u002Ftowardsdatascience.com\u002Four-picks\u002Fhome","type":"TOPIC_PAGE","__typename":"NavItem"},"Collection:7f60cf5620c9.navItems.6":{"title":"More","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fmore\u002Fhome","type":"TOPIC_PAGE","__typename":"NavItem"},"Collection:7f60cf5620c9.navItems.7":{"title":"Contribute","url":"https:\u002F\u002Ftowardsdatascience.com\u002Fcontribute\u002Fhome","type":"EXTERNAL_LINK_NAV_ITEM","__typename":"NavItem"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum":{"backgroundColor":"#FF355876","colorPoints":[{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.0","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.1","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.2","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.3","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.4","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.5","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.6","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.7","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.8","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.9","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.10","typename":"ColorPoint"}],"__typename":"ColorSpectrum"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.0":{"color":"#FF355876","point":0,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.1":{"color":"#FF4D6C88","point":0.1,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.2":{"color":"#FF637F99","point":0.2,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.3":{"color":"#FF7791A8","point":0.3,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.4":{"color":"#FF8CA2B7","point":0.4,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.5":{"color":"#FF9FB3C6","point":0.5,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.6":{"color":"#FFB2C3D4","point":0.6,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.7":{"color":"#FFC5D2E1","point":0.7,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.8":{"color":"#FFD7E2EE","point":0.8,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.9":{"color":"#FFE9F1FA","point":0.9,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum.colorPoints.10":{"color":"#FFFBFFFF","point":1,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette":{"tintBackgroundSpectrum":{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.tintBackgroundSpectrum","typename":"ColorSpectrum"},"__typename":"ColorPalette","defaultBackgroundSpectrum":{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum","typename":"ColorSpectrum"},"highlightSpectrum":{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum","typename":"ColorSpectrum"}},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum":{"backgroundColor":"#FFFFFFFF","colorPoints":[{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.0","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.1","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.2","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.3","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.4","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.5","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.6","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.7","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.8","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.9","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.10","typename":"ColorPoint"}],"__typename":"ColorSpectrum"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.0":{"color":"#FF668AAA","point":0,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.1":{"color":"#FF61809D","point":0.1,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.2":{"color":"#FF5A7690","point":0.2,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.3":{"color":"#FF546C83","point":0.3,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.4":{"color":"#FF4D6275","point":0.4,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.5":{"color":"#FF455768","point":0.5,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.6":{"color":"#FF3D4C5A","point":0.6,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.7":{"color":"#FF34414C","point":0.7,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.8":{"color":"#FF2B353E","point":0.8,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.9":{"color":"#FF21282F","point":0.9,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.defaultBackgroundSpectrum.colorPoints.10":{"color":"#FF161B1F","point":1,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum":{"backgroundColor":"#FFFFFFFF","colorPoints":[{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.0","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.1","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.2","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.3","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.4","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.5","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.6","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.7","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.8","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.9","typename":"ColorPoint"},{"type":"id","generated":true,"id":"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.10","typename":"ColorPoint"}],"__typename":"ColorSpectrum"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.0":{"color":"#FFEDF4FC","point":0,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.1":{"color":"#FFE9F2FD","point":0.1,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.2":{"color":"#FFE6F1FD","point":0.2,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.3":{"color":"#FFE2EFFD","point":0.3,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.4":{"color":"#FFDFEEFD","point":0.4,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.5":{"color":"#FFDBECFE","point":0.5,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.6":{"color":"#FFD7EBFE","point":0.6,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.7":{"color":"#FFD4E9FE","point":0.7,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.8":{"color":"#FFD0E7FF","point":0.8,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.9":{"color":"#FFCCE6FF","point":0.9,"__typename":"ColorPoint"},"$Collection:7f60cf5620c9.colorPalette.highlightSpectrum.colorPoints.10":{"color":"#FFC8E4FF","point":1,"__typename":"ColorPoint"},"$Post:fcddc4b6fe56.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}})":{"isLockedPreviewOnly":false,"validatedShareKey":"","__typename":"PostContent","bodyModel":{"type":"id","generated":true,"id":"$Post:fcddc4b6fe56.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel","typename":"RichText"}},"$Post:fcddc4b6fe56.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel.sections.0":{"name":"5a37","startIndex":0,"textLayout":null,"imageLayout":null,"backgroundImage":null,"videoLayout":null,"backgroundVideo":null,"__typename":"Section"},"$Post:fcddc4b6fe56.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel":{"sections":[{"type":"id","generated":true,"id":"$Post:fcddc4b6fe56.content({\"postMeteringOptions\":{\"referrer\":\"https:\u002F\u002Fwww.google.com\u002F\"}}).bodyModel.sections.0","typename":"Section"}],"paragraphs":[{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_0","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_1","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_2","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_3","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_4","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_5","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_6","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_7","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_8","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_9","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_10","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_11","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_12","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_13","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_14","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_15","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_16","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_17","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_18","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_19","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_20","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_21","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_22","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_23","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_24","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_25","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_26","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_27","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_28","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_29","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_30","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_31","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_32","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_33","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_34","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_35","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_36","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_37","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_38","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_39","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_40","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_41","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_42","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_43","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_44","typename":"Paragraph"},{"type":"id","generated":false,"id":"Paragraph:2ee44278ac49_45","typename":"Paragraph"}],"__typename":"RichText"},"Paragraph:2ee44278ac49_0":{"id":"2ee44278ac49_0","name":"f807","type":"H3","href":null,"layout":null,"metadata":null,"text":"Simple Reinforcement Learning: Q-learning","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_1":{"id":"2ee44278ac49_1","name":"5ce6","type":"IMG","href":null,"layout":"INSET_CENTER","metadata":{"type":"id","generated":false,"id":"ImageMetadata:1*OjizsKNU6_LyM3QW8is0Sg.jpeg","typename":"ImageMetadata"},"text":"Typical Exploring Image for RL - Credit @mike.shots","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_1.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"ImageMetadata:1*OjizsKNU6_LyM3QW8is0Sg.jpeg":{"id":"1*OjizsKNU6_LyM3QW8is0Sg.jpeg","originalHeight":3448,"originalWidth":4592,"focusPercentX":null,"focusPercentY":null,"alt":null,"__typename":"ImageMetadata"},"Paragraph:2ee44278ac49_1.markups.0":{"type":"A","start":40,"end":51,"href":"https:\u002F\u002Fwww.instagram.com\u002Fmike.shots\u002F","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_2":{"id":"2ee44278ac49_2","name":"7e6f","type":"H3","href":null,"layout":null,"metadata":null,"text":"Introduction","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_2.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_2.markups.0":{"type":"STRONG","start":0,"end":12,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_3":{"id":"2ee44278ac49_3","name":"2fe7","type":"P","href":null,"layout":null,"metadata":null,"text":"One of my favorite algorithms that I learned while taking a reinforcement learning course was q-learning. Probably because it was the easiest for me to understand and code, but also because it seemed to make sense. In this quick post I’ll discuss q-learning and provide the basic background to understanding the algorithm.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_4":{"id":"2ee44278ac49_4","name":"127f","type":"H3","href":null,"layout":null,"metadata":null,"text":"What is q-learning?","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_4.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_4.markups.0":{"type":"STRONG","start":0,"end":19,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_5":{"id":"2ee44278ac49_5","name":"1ce0","type":"P","href":null,"layout":null,"metadata":null,"text":"Q-learning is an off policy reinforcement learning algorithm that seeks to find the best action to take given the current state. It’s considered off-policy because the q-learning function learns from actions that are outside the current policy, like taking random actions, and therefore a policy isn’t needed. More specifically, q-learning seeks to learn a policy that maximizes the total reward.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_6":{"id":"2ee44278ac49_6","name":"e050","type":"H3","href":null,"layout":null,"metadata":null,"text":"What’s ‘Q’?","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_6.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_6.markups.0":{"type":"STRONG","start":0,"end":11,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_7":{"id":"2ee44278ac49_7","name":"cc81","type":"P","href":null,"layout":null,"metadata":null,"text":"The ‘q’ in q-learning stands for quality. Quality in this case represents how useful a given action is in gaining some future reward.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_8":{"id":"2ee44278ac49_8","name":"7464","type":"H3","href":null,"layout":null,"metadata":null,"text":"Create a q-table","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_8.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_8.markups.0":{"type":"STRONG","start":0,"end":16,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_9":{"id":"2ee44278ac49_9","name":"2652","type":"P","href":null,"layout":null,"metadata":null,"text":"When q-learning is performed we create what’s called a q-table or matrix that follows the shape of [state, action] and we initialize our values to zero. We then update and store our q-values after an episode. This q-table becomes a reference table for our agent to select the best action based on the q-value.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_9.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_9.markups.1","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_9.markups.2","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_9.markups.0":{"type":"CODE","start":99,"end":114,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_9.markups.1":{"type":"EM","start":55,"end":62,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_9.markups.2":{"type":"EM","start":182,"end":191,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_10":{"id":"2ee44278ac49_10","name":"2ffa","type":"PRE","href":null,"layout":null,"metadata":null,"text":"import numpy as np","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_11":{"id":"2ee44278ac49_11","name":"6b60","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# Initialize q-table values to 0","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_12":{"id":"2ee44278ac49_12","name":"d086","type":"PRE","href":null,"layout":null,"metadata":null,"text":"Q = np.zeros((state_size, action_size))","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_13":{"id":"2ee44278ac49_13","name":"236b","type":"H3","href":null,"layout":null,"metadata":null,"text":"Q-learning and making updates","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_13.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_13.markups.0":{"type":"STRONG","start":0,"end":29,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_14":{"id":"2ee44278ac49_14","name":"aa0d","type":"P","href":null,"layout":null,"metadata":null,"text":"The next step is simply for the agent to interact with the environment and make updates to the state action pairs in our q-table Q[state, action].","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_14.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_14.markups.0":{"type":"CODE","start":129,"end":145,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_15":{"id":"2ee44278ac49_15","name":"0bf9","type":"P","href":null,"layout":null,"metadata":null,"text":"Taking Action: Explore or Exploit","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_15.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_15.markups.0":{"type":"EM","start":0,"end":33,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_16":{"id":"2ee44278ac49_16","name":"b46f","type":"P","href":null,"layout":null,"metadata":null,"text":"An agent interacts with the environment in 1 of 2 ways. The first is to use the q-table as a reference and view all possible actions for a given state. The agent then selects the action based on the max value of those actions. This is known as exploiting since we use the information we have available to us to make a decision.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_16.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_16.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_16.markups.0":{"type":"STRONG","start":244,"end":254,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_16.markups.1":{"type":"EM","start":244,"end":254,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_17":{"id":"2ee44278ac49_17","name":"2f0d","type":"P","href":null,"layout":null,"metadata":null,"text":"The second way to take action is to act randomly. This is called exploring. Instead of selecting actions based on the max future reward we select an action at random. Acting randomly is important because it allows the agent to explore and discover new states that otherwise may not be selected during the exploitation process. You can balance exploration\u002Fexploitation using epsilon (ε) and setting the value of how often you want to explore vs exploit. Here’s some rough code that will depend on how the state and action space are setup.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_17.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_17.markups.1","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_17.markups.2","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_17.markups.0":{"type":"STRONG","start":65,"end":74,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_17.markups.1":{"type":"EM","start":65,"end":74,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_17.markups.2":{"type":"EM","start":383,"end":384,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_18":{"id":"2ee44278ac49_18","name":"e4a9","type":"PRE","href":null,"layout":null,"metadata":null,"text":"import random","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_19":{"id":"2ee44278ac49_19","name":"26ca","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# Set the percent you want to explore\nepsilon = 0.2","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_20":{"id":"2ee44278ac49_20","name":"37ce","type":"PRE","href":null,"layout":null,"metadata":null,"text":"if random.uniform(0, 1) \u003C epsilon:\n    \"\"\"\n    Explore: select a random action","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_21":{"id":"2ee44278ac49_21","name":"247c","type":"PRE","href":null,"layout":null,"metadata":null,"text":"    \"\"\"\nelse:\n    \"\"\"\n    Exploit: select the action with max value (future reward)","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_22":{"id":"2ee44278ac49_22","name":"37da","type":"PRE","href":null,"layout":null,"metadata":null,"text":"    \"\"\"","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_23":{"id":"2ee44278ac49_23","name":"ace4","type":"P","href":null,"layout":null,"metadata":null,"text":"Updating the q-table","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_23.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_23.markups.0":{"type":"EM","start":0,"end":20,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_24":{"id":"2ee44278ac49_24","name":"1389","type":"P","href":null,"layout":null,"metadata":null,"text":"The updates occur after each step or action and ends when an episode is done. Done in this case means reaching some terminal point by the agent. A terminal state for example can be anything like landing on a checkout page, reaching the end of some game, completing some desired objective, etc. The agent will not learn much after a single episode, but eventually with enough exploring (steps and episodes) it will converge and learn the optimal q-values or q-star (Q∗).","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_24.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_24.markups.0":{"type":"CODE","start":465,"end":467,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_25":{"id":"2ee44278ac49_25","name":"33fe","type":"P","href":null,"layout":null,"metadata":null,"text":"Here are the 3 basic steps:","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_26":{"id":"2ee44278ac49_26","name":"79f0","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Agent starts in a state (s1) takes an action (a1) and receives a reward (r1)","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_27":{"id":"2ee44278ac49_27","name":"a229","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Agent selects action by referencing Q-table with highest value (max) OR by random (epsilon, ε)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_27.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_27.markups.0":{"type":"STRONG","start":69,"end":71,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_28":{"id":"2ee44278ac49_28","name":"e765","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Update q-values","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_29":{"id":"2ee44278ac49_29","name":"e56f","type":"P","href":null,"layout":null,"metadata":null,"text":"Here is the basic update rule for q-learning:","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_30":{"id":"2ee44278ac49_30","name":"1bdc","type":"PRE","href":null,"layout":null,"metadata":null,"text":"# Update q values","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_31":{"id":"2ee44278ac49_31","name":"fb32","type":"PRE","href":null,"layout":null,"metadata":null,"text":"Q[state, action] = Q[state, action] + lr * (reward + gamma * np.max(Q[new_state, :]) — Q[state, action])","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_32":{"id":"2ee44278ac49_32","name":"5361","type":"P","href":null,"layout":null,"metadata":null,"text":"In the update above there are a couple variables that we haven’t mentioned yet. Whats happening here is we adjust our q-values based on the difference between the discounted new values and the old values. We discount the new values using gamma and we adjust our step size using learning rate (lr). Below are some references.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_33":{"id":"2ee44278ac49_33","name":"6906","type":"P","href":null,"layout":null,"metadata":null,"text":"Learning Rate: lr or learning rate, often referred to as alpha or α, can simply be defined as how much you accept the new value vs the old value. Above we are taking the difference between new and old and then multiplying that value by the learning rate. This value then gets added to our previous q-value which essentially moves it in the direction of our latest update.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_33.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_33.markups.1","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_33.markups.2","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_33.markups.3","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_33.markups.0":{"type":"CODE","start":15,"end":17,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_33.markups.1":{"type":"STRONG","start":0,"end":14,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_33.markups.2":{"type":"EM","start":57,"end":63,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_33.markups.3":{"type":"EM","start":65,"end":66,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_34":{"id":"2ee44278ac49_34","name":"4af3","type":"P","href":null,"layout":null,"metadata":null,"text":"Gamma: gamma or γ is a discount factor. It’s used to balance immediate and future reward. From our update rule above you can see that we apply the discount to the future reward. Typically this value can range anywhere from 0.8 to 0.99.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_34.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_34.markups.1","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_34.markups.2","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_34.markups.0":{"type":"CODE","start":7,"end":12,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_34.markups.1":{"type":"STRONG","start":0,"end":6,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_34.markups.2":{"type":"EM","start":16,"end":18,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_35":{"id":"2ee44278ac49_35","name":"49cf","type":"P","href":null,"layout":null,"metadata":null,"text":"Reward: reward is the value received after completing a certain action at a given state. A reward can happen at any given time step or only at the terminal time step.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_35.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_35.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_35.markups.0":{"type":"CODE","start":8,"end":14,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_35.markups.1":{"type":"STRONG","start":0,"end":7,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_36":{"id":"2ee44278ac49_36","name":"6f83","type":"P","href":null,"layout":null,"metadata":null,"text":"Max: np.max() uses the numpy library and is taking the maximum of the future reward and applying it to the reward for the current state. What this does is impact the current action by the possible future reward. This is the beauty of q-learning. We’re allocating future reward to current actions to help the agent select the highest return action at any given state.","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_36.markups.0","typename":"Markup"},{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_36.markups.1","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_36.markups.0":{"type":"CODE","start":5,"end":13,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_36.markups.1":{"type":"STRONG","start":0,"end":4,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_37":{"id":"2ee44278ac49_37","name":"b164","type":"P","href":null,"layout":null,"metadata":null,"text":"Conclusion","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_37.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_37.markups.0":{"type":"STRONG","start":0,"end":10,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_38":{"id":"2ee44278ac49_38","name":"6a99","type":"P","href":null,"layout":null,"metadata":null,"text":"Well that’s it, short and sweet (hopefully). We discussed that q-learning is an off-policy reinforcement learning algorithm. We show the basic update rule for q-learning using some basic python syntax and we reviewed the required inputs to the algorithm. We learned that q-learning uses future rewards to influence the current action given a state and therefore helps the agent select best actions that maximize total reward.","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_39":{"id":"2ee44278ac49_39","name":"1bfd","type":"P","href":null,"layout":null,"metadata":null,"text":"There is a lot more on q-learning but hopefully this is enough to get you started and interested in learning more. I added several resources below that I found helpful when learning about q-learning. Enjoy!","hasDropCap":null,"dropCapImage":null,"markups":[],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_40":{"id":"2ee44278ac49_40","name":"8087","type":"P","href":null,"layout":null,"metadata":null,"text":"Resources","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_40.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_40.markups.0":{"type":"STRONG","start":0,"end":9,"href":null,"anchorType":null,"userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_41":{"id":"2ee44278ac49_41","name":"d3f7","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Great RL and q-learning example using the OpenAI Gym taxi environment","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_41.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_41.markups.0":{"type":"A","start":42,"end":58,"href":"https:\u002F\u002Fwww.learndatasci.com\u002Ftutorials\u002Freinforcement-q-learning-scratch-python-openai-gym\u002F","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_42":{"id":"2ee44278ac49_42","name":"17fc","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Reinforcement Learning: An Introduction (free book by Sutton)","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_42.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_42.markups.0":{"type":"A","start":0,"end":39,"href":"http:\u002F\u002Fwww.incompleteideas.net\u002Fbook\u002FRLbook2018trimmed.pdf","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_43":{"id":"2ee44278ac49_43","name":"9313","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Quora Q-learning","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_43.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_43.markups.0":{"type":"A","start":6,"end":16,"href":"https:\u002F\u002Fwww.quora.com\u002FHow-does-Q-learning-work-1","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_44":{"id":"2ee44278ac49_44","name":"65f1","type":"OLI","href":null,"layout":null,"metadata":null,"text":"Wikipedia Q-learning","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_44.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_44.markups.0":{"type":"A","start":10,"end":20,"href":"https:\u002F\u002Fen.wikipedia.org\u002Fwiki\u002FQ-learning","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Paragraph:2ee44278ac49_45":{"id":"2ee44278ac49_45","name":"3009","type":"OLI","href":null,"layout":null,"metadata":null,"text":"David Silver’s lectures on RL","hasDropCap":null,"dropCapImage":null,"markups":[{"type":"id","generated":true,"id":"Paragraph:2ee44278ac49_45.markups.0","typename":"Markup"}],"__typename":"Paragraph","iframe":null,"mixtapeMetadata":null},"Paragraph:2ee44278ac49_45.markups.0":{"type":"A","start":15,"end":29,"href":"http:\u002F\u002Fwww0.cs.ucl.ac.uk\u002Fstaff\u002Fd.silver\u002Fweb\u002FTeaching.html","anchorType":"LINK","userId":null,"linkMetadata":null,"__typename":"Markup"},"Tag:machine-learning":{"id":"machine-learning","displayTitle":"Machine Learning","__typename":"Tag"},"Tag:reinforcement-learning":{"id":"reinforcement-learning","displayTitle":"Reinforcement Learning","__typename":"Tag"},"Tag:q-learning":{"id":"q-learning","displayTitle":"Q Learning","__typename":"Tag"},"Tag:data-science":{"id":"data-science","displayTitle":"Data Science","__typename":"Tag"},"$Post:fcddc4b6fe56.responses":{"stream":[],"__typename":"StreamConnection"},"ImageMetadata:1*ChFMdf--f5jbm-AYv6VdYA@2x.png":{"id":"1*ChFMdf--f5jbm-AYv6VdYA@2x.png","__typename":"ImageMetadata"},"$Post:fcddc4b6fe56.previewContent":{"subtitle":"Introduction","__typename":"PreviewContent"}}</script><script src="./Simple Reinforcement Learning_ Q-learning - Towards Data Science_files/manifest.2abb7213.js.download"></script><script src="./Simple Reinforcement Learning_ Q-learning - Towards Data Science_files/vendors_main.4ef3f2b0.chunk.js.download"></script><script src="./Simple Reinforcement Learning_ Q-learning - Towards Data Science_files/main.76290c68.chunk.js.download"></script><script src="./Simple Reinforcement Learning_ Q-learning - Towards Data Science_files/vendors_screen.collection.packageBuilder_screen.collection.styleEditor_screen.landingpages.pres45_sc_643621df.0eae2f52.chunk.js.download"></script>
<script src="./Simple Reinforcement Learning_ Q-learning - Towards Data Science_files/vendors_screen.post_screen.post.amp_screen.post.series_screen.sequence.post.6d20df7f.chunk.js.download"></script>
<script src="./Simple Reinforcement Learning_ Q-learning - Towards Data Science_files/screen.collection.packageBuilder_screen.collection.styleEditor_screen.landingpages.pres45_screen.lan_a6034ba3.78b3ec15.chunk.js.download"></script>
<script src="./Simple Reinforcement Learning_ Q-learning - Towards Data Science_files/screen.collection.packageBuilder_screen.collection.styleEditor_screen.landingpages.pres45_screen.lan_674be8d4.ac75e4cc.chunk.js.download"></script>
<script src="./Simple Reinforcement Learning_ Q-learning - Towards Data Science_files/screen.post.c9920a40.chunk.js.download"></script><script>window.main();</script><script src="./Simple Reinforcement Learning_ Q-learning - Towards Data Science_files/p.js.download" async="" id="parsely-cf"></script></body></html>